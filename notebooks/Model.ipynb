{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick\\Desktop\\tfcv\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Concatenate, UpSampling2D, Add\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from initializers import PriorProbability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(f'Tensorflow Version: {tf.__version__}')\n",
    "print(f'TFDS Version: {tfds.__version__}')\n",
    "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 1. Tensorflow Datasets (TFDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "train, info = tfds.load('wider_face', split=\"train\", with_info=True)\n",
    "validation = tfds.load('wider_face', split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# data comes in tuples with a 28x28x1 array of uint8 for the images and 1 uint64 label\n",
    "train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ex = train.take(2)\n",
    "imgs = [x['image'].numpy() for x in ex]\n",
    "faces = [x['faces'] for x in ex]\n",
    "faces[1]['bbox'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def plot_images(ds=train, n=5, fig_size=128, font_size=32, show_boxes=False):\n",
    "    \"\"\"Plot n samples of images\"\"\"\n",
    "    examples = ds.take(n)\n",
    "    # 28x28 to visualize (dont need the color channel)\n",
    "    \n",
    "    imgs = [x['image'].numpy() for x in examples]\n",
    "     # use our int2str to get string of int labels\n",
    "    labels = [x['image/filename'].numpy() for x in examples]\n",
    "    # separate the class since it is pretty long\n",
    "    labels = [list(os.path.split(l))[-1:][0] for l in labels]\n",
    "    all_faces = [x['faces']['bbox'] for x in examples]\n",
    "    \n",
    "    def transform_bbox(bbox, img_width, img_height):\n",
    "        #  (ymin, xmin, ymax, xmax) -> (xmin, ymin, w, h)\n",
    "        [x_min, x_max] = np.array([x_min, x_max])*img_width\n",
    "        [y_min, y_max] = np.array([y_min, y_max])*img_height\n",
    "        w = (xmax - xmin) \n",
    "        h = ymax - ymin \n",
    "        return [xmin, ymin, w, h]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(imgs), figsize=(fig_size, fig_size))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax, label, faces in zip(imgs, axes, labels, all_faces):\n",
    "        ax.imshow(img)\n",
    "        #ax.set_title(label, color='w', fontsize=font_size)\n",
    "        ax.set_title(str(faces.shape[0]), color='w', fontsize=font_size)\n",
    "        ax.axis('off')\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "faces=plot_images(n=10, font_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def plot_bbox(ds=train, n=100, _index=0):\n",
    "    \"\"\"Plot bbox on a photo\"\"\"\n",
    "    ex = ds.take(n)\n",
    "    \n",
    "    img = [x['image'].numpy() for x in ex][_index]\n",
    "    faces = [x['faces']['bbox'].numpy().tolist() for x in ex][_index]\n",
    "    \n",
    "    def transform_bbox(bbox, img_width, img_height):\n",
    "        #  (ymin, xmin, ymax, xmax) -> (xmin, ymin, w, h)\n",
    "        xmin = bbox[1]*img_width\n",
    "        ymin = bbox[0]*img_height\n",
    "        xmax = bbox[3]*img_width\n",
    "        ymax = bbox[2]*img_height\n",
    "        \n",
    "        w = (xmax - xmin) \n",
    "        h = ymax - ymin \n",
    "        return [xmin, ymin, w, h]\n",
    "    \n",
    "    #fig, ax = plt.subplots(1, figsize=(fig_size, fig_size))\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "        \n",
    "    for bbox in faces:\n",
    "        bbox = transform_bbox(bbox, img.shape[0], img.shape[1])\n",
    "        rect = patches.Rectangle((bbox[0], bbox[1]),bbox[3], bbox[2], linewidth=1, edgecolor='g', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_bbox(_index=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def preprocess(features):\n",
    "    image = features['image']\n",
    "    image = tf.image.resize(image, (640, 640))\n",
    "    image = image / 255.0\n",
    "    \n",
    "    bboxes = features['faces']['bbox']\n",
    "    bboxes = tf.concat(bboxes, axis=0)\n",
    "    \n",
    "    bboxes = tf.gather(bboxes, indices=[1, 0, 3, 2], axis=1) # I created the dataset wrong; should be (xmin, ymin, xmax, ymax)\n",
    "    return image, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# train = train.shuffle(buffer_size=128).map(preprocess).batch(32)\n",
    "\n",
    "# train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# train = train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for ex in train.take(1):\n",
    "    print(preprocess(ex)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 2.1 Pretrained Model (Backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 4d473c1dd8becc155b73f8504c6f6626 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 17s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = (640, 640, 3)\n",
    "\n",
    "backbone_model = tf.keras.applications.ResNet50(weights='imagenet',\n",
    "                                                input_shape=input_shape, \n",
    "                                                include_top=False)\n",
    "#backbone_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = backbone_model(inputs, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# to get this to work for me on windows i needed to conda install pydotplus and python-graphviz then\n",
    "#change the path in pydotplut/graphviz.py as in https://datascience.stackexchange.com/questions/37428/graphviz-not-working-when-imported-inside-pydotplus-graphvizs-executables-not/61840#61840?newreg=fff7d63feca2460ab2062f1a9c450adb\n",
    "tf.keras.utils.plot_model(backbone_model, show_shapes=True, show_layer_names=True, to_file='object_detection/images/resnet50.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 640, 640, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 646, 646, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 320, 320, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 320, 320, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 320, 320, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 322, 322, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 160, 160, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 160, 160, 64) 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 160, 160, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 160, 160, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 160, 160, 64) 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 160, 160, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 160, 160, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 160, 160, 256 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 160, 160, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 160, 160, 256 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 160, 160, 256 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 160, 160, 256 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 160, 160, 256 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 160, 160, 64) 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 160, 160, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 160, 160, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 160, 160, 64) 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 160, 160, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 160, 160, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 160, 160, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 160, 160, 256 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 160, 160, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 160, 160, 256 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 160, 160, 64) 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 160, 160, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 160, 160, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 160, 160, 64) 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 160, 160, 64) 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 160, 160, 64) 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 160, 160, 256 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 160, 160, 256 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 160, 160, 256 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 160, 160, 256 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 80, 80, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 80, 80, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 80, 80, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 80, 80, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 80, 80, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 80, 80, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 80, 80, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 80, 80, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 80, 80, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 80, 80, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 80, 80, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 80, 80, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 80, 80, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 80, 80, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 80, 80, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 80, 80, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 80, 80, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 80, 80, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 80, 80, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 80, 80, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 80, 80, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 80, 80, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 80, 80, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 80, 80, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 80, 80, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 80, 80, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 80, 80, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 80, 80, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 80, 80, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 80, 80, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 80, 80, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 80, 80, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 80, 80, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 80, 80, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 80, 80, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 80, 80, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 80, 80, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 80, 80, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 80, 80, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 80, 80, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 80, 80, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 80, 80, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 40, 40, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 40, 40, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 40, 40, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 40, 40, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 40, 40, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 40, 40, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 40, 40, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 40, 40, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 40, 40, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 40, 40, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 40, 40, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 40, 40, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 40, 40, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 40, 40, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 40, 40, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 40, 40, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 40, 40, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 40, 40, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 40, 40, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 40, 40, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 40, 40, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 40, 40, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 40, 40, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 40, 40, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 40, 40, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 40, 40, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 40, 40, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 40, 40, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 40, 40, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 40, 40, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 40, 40, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 40, 40, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 40, 40, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 40, 40, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 40, 40, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 40, 40, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 40, 40, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 40, 40, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 40, 40, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 40, 40, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 40, 40, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 40, 40, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 40, 40, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 40, 40, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 40, 40, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 40, 40, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 40, 40, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 40, 40, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 40, 40, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 40, 40, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 40, 40, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 20, 20, 512)  524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 20, 20, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 20, 20, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 20, 20, 512)  2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 20, 20, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 20, 20, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 20, 20, 2048) 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 20, 20, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 20, 20, 2048) 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 20, 20, 2048) 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 20, 20, 2048) 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 20, 20, 2048) 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 20, 20, 512)  1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 20, 20, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 20, 20, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 20, 20, 512)  2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 20, 20, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 20, 20, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 20, 20, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 20, 20, 2048) 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 20, 20, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 20, 20, 2048) 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 20, 20, 512)  1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 20, 20, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 20, 20, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 20, 20, 512)  2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 20, 20, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 20, 20, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 20, 20, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 20, 20, 2048) 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 20, 20, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 20, 20, 2048) 0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "backbone_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 2.2 Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#model subclassing not working b/c Add layer doesnt catch shape changes\n",
    "tf.keras.backend.clear_session() \n",
    "\n",
    "class RetinaFace(tf.keras.Model):\n",
    "    def __init__(self, input_shape=(640, 640, 3)):\n",
    "        super(RetinaFace, self).__init__()\n",
    "        \n",
    "        self.backbone_model = tf.keras.applications.ResNet152(weights='imagenet', \n",
    "                                                              input_shape=input_shape,\n",
    "                                                              include_top=False)\n",
    "        self.backbone_model.trainable = False # freeze all layers of ResNet\n",
    "        self.p2_lateral_conv = Conv2D(256, kernel_size=(1, 1), strides=1, padding='same', activation=None, name='p2_lateral_conv')\n",
    "        self.p3_lateral_conv = Conv2D(256, kernel_size=(1, 1), strides=1, padding='same', activation=None, name='p3_lateral_conv')\n",
    "        self.p4_lateral_conv = Conv2D(256, kernel_size=(1, 1), strides=1, padding='same', activation=None, name='p4_lateral_conv')\n",
    "        self.p5_lateral_conv = Conv2D(256, kernel_size=(1, 1), strides=1, padding='same', activation=None, name='p5_lateral_conv')\n",
    "        # glorot same as xavier\n",
    "        self.p6_lateral_conv = Conv2D(256, kernel_size=(3, 3), strides=2, padding='same', activation=None, kernel_initializer='glorot_normal', name='p6_lateral_conv')\n",
    "    \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        anchors = Anchors()\n",
    "        anchors = anchors.generate_all_anchors()\n",
    "        print(anchors.shape)\n",
    "        \n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        x = self.backbone_model(inputs)\n",
    "        p6 = self.p6_lateral_conv(x)\n",
    "        p5 = self.p5_lateral_conv(x)\n",
    "        \n",
    "        p4_lateral_conv = self.p4_lateral_conv(self.backbone_model.get_layer('conv4_block36_out').output)\n",
    "        p4_lateral_conv = tf.reshape(p4_lateral_conv, [batch_size, 40, 40, 256])\n",
    "        p5_upsampled = UpSampling2D(size=(2, 2), name='p5_upsampled')(p5)\n",
    "        p4_add = Add(name='p4_add')([p4_lateral_conv, p5_upsampled])\n",
    "        p4 = Conv2D(256, kernel_size=(3, 3), strides=1, padding='same', activation=None, name='p4_conv_out')(p4_add)\n",
    "        \n",
    "        p3_lateral_conv = self.p3_lateral_conv(self.backbone_model.get_layer('conv3_block8_out').output)\n",
    "        p3_lateral_conv = tf.reshape(p3_lateral_conv, [batch_size, 80, 80, 256])\n",
    "        p4_upsampled = UpSampling2D(size=(2, 2), name='p4_upsampled')(p4)\n",
    "        p3_add = Add(name='p3_add')([p3_lateral_conv, p4_upsampled])\n",
    "        p3 = Conv2D(256, kernel_size=(3, 3), strides=1, padding='same', activation=None, name='p3_conv_out')(p3_add)\n",
    "        \n",
    "        p2_lateral_conv = self.p2_lateral_conv(self.backbone_model.get_layer('conv2_block3_out').output)\n",
    "        p2_lateral_conv = tf.reshape(p2_lateral_conv, [batch_size, 160, 160, 256])\n",
    "        p3_upsampled = UpSampling2D(size=(2, 2), name='p3_upsampled')(p3)\n",
    "        p2_add = Add(name='p2_add')([p2_lateral_conv, p3_upsampled])\n",
    "        p2 = Conv2D(256, kernel_size=(3, 3), strides=1, padding='same', activation=None, name='p2_conv_out')(p2_add)\n",
    "        \n",
    "        features = [p2, p3, p4, p5, p6]\n",
    "        \n",
    "        #return features\n",
    "\n",
    "        # K=2 since face or not face\n",
    "        classification_outputs = []\n",
    "        for feature_layer in features:\n",
    "            classification_outputs.append(ClassificationSubnet(K=2, A=3, prior=.01)(feature_layer))\n",
    "        classification_outputs = tf.keras.layers.Concatenate(axis=1, name='classification_outputs')(classification_outputs)\n",
    "        \n",
    "        # bounding box regression\n",
    "        regression_outputs = []\n",
    "        for feature_layer in features:\n",
    "            regression_outputs.append(RegressionSubnet(n_landmarks=4, A=3)(feature_layer))\n",
    "        regression_outputs = tf.keras.layers.Concatenate(axis=1, name='regression_outputs')(regression_outputs)\n",
    "        print(regression_outputs.shape)\n",
    "#         # facial landmark regression\n",
    "#         landmarks_outputs = []\n",
    "#         for feature_layer in features:\n",
    "#             landmarks_outputs.append(RegressionSubnet(n_landmarks=5, A=3)(feature_layer))\n",
    "        #return features    \n",
    "        #return classification_outputs, regression_outputs\n",
    "        \n",
    "         # apply predicted regression to anchors\n",
    "        boxes = RegressBoxes(name='boxes')([anchors, regression_outputs])\n",
    "        boxes = ClipBoxes(name='clipped_boxes')([model.inputs[0], boxes])\n",
    "        \n",
    "        detections = FilterDetections(nms                   = nms,\n",
    "                                      class_specific_filter = class_specific_filter,\n",
    "                                      name                  = 'filtered_detections',\n",
    "                                      nms_threshold         = nms_threshold,\n",
    "                                      score_threshold       = score_threshold,\n",
    "                                      max_detections        = max_detections,\n",
    "                                      parallel_iterations   = parallel_iterations)([boxes, classification])\n",
    "        return detections\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        #now we need to filter the ones from the anchors\n",
    "    \n",
    "#     def focal_loss():\n",
    "#         pass\n",
    "    \n",
    "#     def train_step(self, data):\n",
    "#         img, bboxes = data\n",
    "#         boxes = RegressBoxes(name='boxes')([anchors, regression])\n",
    "#         boxes = ClipBoxes(name='clipped_boxes')([model.inputs[0], boxes])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         predicted_transforms = self(img)\n",
    "        \n",
    "    \n",
    "model = RetinaFace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for ex in train.take(1):\n",
    "    img, bboxes = preprocess(ex)\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    detections = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Output of FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "for ex in train.take(1):\n",
    "    img, bboxes = preprocess(ex)\n",
    "    features = model(tf.expand_dims(img, 0))\n",
    "    \n",
    "for f in features:\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## 2. 1 Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class ClassificationSubnet(tf.keras.layers.Layer):\n",
    "    \"\"\"Classification Subnet on top of FPN\"\"\"\n",
    "    \n",
    "    def __init__(self, K, A, prior):\n",
    "        super(ClassificationSubnet, self).__init__()\n",
    "        self.K = K\n",
    "        self.A = A\n",
    "        self.prior = prior\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        for i in range(4):\n",
    "                outputs = Conv2D(256, \n",
    "                                 kernel_size=(3, 3), \n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None),\n",
    "                                 bias_initializer='zeros',\n",
    "                                 activation='relu')(outputs)\n",
    "        \n",
    "        outputs = Conv2D(self.K*self.A,\n",
    "                         kernel_size=(3, 3),\n",
    "                         strides=1,\n",
    "                         padding='same',\n",
    "                         kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None),\n",
    "                         bias_initializer=PriorProbability(probability=self.prior),\n",
    "                         activation='relu')(outputs)  # (w x h x C) - (w x h x (K*A))\n",
    "        \n",
    "        # K anchors at each center pixel (width*height)\n",
    "        outputs = tf.keras.layers.Reshape((-1, self.K))(outputs) # (w x h x (K*A)) - (w*h*A, K) \n",
    "        outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# # test\n",
    "for ex in train.take(1):\n",
    "    img, bboxes = preprocess(ex)\n",
    "    classification_outputs, _ = model(tf.expand_dims(img, 0))\n",
    "    \n",
    "total=0\n",
    "for o in classification_outputs:\n",
    "    print(o.shape)\n",
    "    total+=o.shape.as_list()[1]\n",
    "    \n",
    "print(f'\\nTotal: {total} anchors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# OR... (notice it matches the paper)\n",
    "total=0\n",
    "for x in [160, 80, 40, 20, 10]:\n",
    "    total += (x**2)*3\n",
    "print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class RegressionSubnet(tf.keras.layers.Layer):\n",
    "    \"\"\"Regression Subnet on top of FPN\"\"\"\n",
    "    \n",
    "    def __init__(self, n_landmarks, A):\n",
    "        super(RegressionSubnet, self).__init__()\n",
    "        self.n_landmarks = n_landmarks\n",
    "        self.A = A\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        for i in range(4):\n",
    "                outputs = Conv2D(256, \n",
    "                                 kernel_size=(3, 3), \n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None),\n",
    "                                 bias_initializer='zeros',\n",
    "                                 activation='relu')(outputs)\n",
    "        \n",
    "        outputs = Conv2D(self.n_landmarks*self.A,\n",
    "                         kernel_size=(3, 3),\n",
    "                         strides=1,\n",
    "                         padding='same',\n",
    "                         kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None),\n",
    "                         bias_initializer='zeros',\n",
    "                         activation='relu')(outputs)  # (w x h x C) - (w x h x (K*A))\n",
    "        \n",
    "        # K anchors at each center pixel (width*height)\n",
    "        outputs = tf.keras.layers.Reshape((-1, self.n_landmarks))(outputs) # (w x h x (n_landmarks*A)) - (w*h*n_landmarks, K) \n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for ex in train.take(1):\n",
    "    img, bboxes = preprocess(img)\n",
    "    _, regression_outputs = model(tf.expand_dims(img, 0))\n",
    "    \n",
    "for o in regression_outputs:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 3. Anchor Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 3.1 Create Base Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#sizes = [32, 64, 128, 256] # RetinaNet\n",
    "sizes = [16, 32, 64, 128, 256] # RetinaFace since trying to capture smaller faces\n",
    "strides = [4, 8, 16, 32, 64]\n",
    "#ratios  = [0.5, 1, 2] $ RetinaNet\n",
    "ratios = [1] # RetinaFace since most faces are squares\n",
    "scales = [2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "num_anchors = len(ratios) * len(scales)\n",
    "num_anchors\n",
    "\n",
    "anchors = np.zeros((num_anchors, 4))\n",
    "print(f'{anchors.shape[0]} anchors x {anchors.shape[1]} coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "base_size = 16\n",
    "base_size * np.tile(scales, (2, len(ratios))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "anchors[:, 2:] = base_size * np.tile(scales, (2, len(ratios))).T\n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "areas = anchors[:, 2] * anchors[:, 3]\n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "np.repeat(ratios, len(scales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "anchors[:, 2] = np.sqrt(areas / np.repeat(ratios, len(scales)))\n",
    "\n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "anchors[:, 3] = anchors[:, 2] * np.repeat(ratios, len(scales))\n",
    "\n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# transform from (x_ctr, y_ctr, w, h) -> (x1, y1, x2, y2)\n",
    "anchors[:, 0::2] -= np.tile(anchors[:, 2] * 0.5, (2, 1)).T\n",
    "anchors[:, 1::2] -= np.tile(anchors[:, 3] * 0.5, (2, 1)).T\n",
    "\n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 3.2 Create Bounding Boxes to Regress Against (ex: P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#tf.squeeze removes the batch size index\n",
    "p2_features = tf.squeeze(features[0], axis=0)\n",
    "print('p2_features shape:', p2_features.shape)\n",
    "\n",
    "p2_anchors = {'size': sizes[0], 'stride': strides[0], 'ratios': ratios, 'scales': scales}\n",
    "print('p2_anchors:', p2_anchors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**tf.keras.backend.shift**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# notice these are the center pixels\n",
    "stride = p2_anchors['stride']\n",
    "\n",
    "shift_x = (tf.keras.backend.arange(0, p2_features.shape[1], dtype=tf.float32) + tf.keras.backend.constant(0.5, dtype=tf.float32)) * stride\n",
    "shift_y = (tf.keras.backend.arange(0, p2_features.shape[0], dtype=tf.float32) + tf.keras.backend.constant(0.5, dtype=tf.float32)) * stride\n",
    "\n",
    "# a tensor that supports cartesian indexing\n",
    "shift_x, tf.meshgrid(shift_x)\n",
    "shift_y = tf.meshgrid(shift_y)\n",
    "\n",
    "# make sure of 1-dimensionsal \n",
    "shift_x = tf.keras.backend.reshape(shift_x, [-1])\n",
    "shift_y = tf.keras.backend.reshape(shift_y, [-1])\n",
    "\n",
    "#notice this will be the same for shift_y since the height is equal to the width in our input_shape as in RetinaNet\n",
    "print(f'Placing the anchor boxes every {stride} strides on a box of width {p2_features.shape[0]} (output of p2) yields:\\n')\n",
    "print(shift_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "shifts = tf.keras.backend.stack([shift_x, shift_y, shift_x, shift_y], axis=0)\n",
    "shifts = tf.keras.backend.transpose(shifts)\n",
    "\n",
    "print(shifts.shape)\n",
    "print(shifts[:][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_anchors = tf.keras.backend.shape(anchors)[0]\n",
    "print(f'{n_anchors} distinct anchors ({len(ratios)} aspect ratios * {len(scales)} scales)')\n",
    "\n",
    "k = tf.keras.backend.shape(shifts)[0]\n",
    "print(f'k={k} (center pixels on low resolution images which anchors will repeat on)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "anchors = tf.cast(anchors, dtype=tf.float32)\n",
    "shifts = tf.cast(shifts, dtype=tf.float32)\n",
    "\n",
    "shifted_anchors = tf.keras.backend.reshape(anchors, [1, n_anchors, 4]) + tf.keras.backend.reshape(shifts, [k, 1, 4])\n",
    "shifted_anchors = tf.keras.backend.reshape(shifted_anchors, [k * n_anchors, 4])\n",
    "\n",
    "print('Given our initial anchor box shapes, we can add them to each of our coordinates or shift according to the stride')\n",
    "print(f'{n_anchors} anchors at {shifts.shape[0]} centers/shifts = {shifted_anchors.shape[0]} total anchors for P2 with {shifted_anchors.shape[1]} coordinates each corresponding to ()\\n')\n",
    "print(shifted_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.tile(tf.keras.backend.expand_dims(shifted_anchors, axis=0), (160, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# draw them on image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 3.3 Modularize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class Anchors(tf.keras.layers.Layer):\n",
    "    \"\"\"Create anchor boxes for Object Detection\"\"\"\n",
    "    \n",
    "    def __init__(self, resolution=None, sizes=None, strides=None, ratios=None, scales=None):\n",
    "        \"\"\"Initiliaze parameters for Anchor Boxes\"\"\"\n",
    "        # strides and sizes align with FPN feature outputs (p2-pn)\n",
    "        if not resolution:\n",
    "            self.resolution = 640\n",
    "        if not sizes:\n",
    "            self.sizes = [16, 32, 64, 128, 256]\n",
    "        if not strides:\n",
    "            self.strides = [4, 8, 16, 32, 64]\n",
    "        # ratios and scales applied to all feature levels from FPN output\n",
    "        if not ratios:\n",
    "            #self.ratios  = [0.5, 1, 2]\n",
    "            self.ratios = [1] #used in RetinaFace since faces are typically square-like\n",
    "        if not scales:\n",
    "            self.scales  = [2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]\n",
    "            \n",
    "        self.n_anchors = len(self.ratios) * len(self.scales)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def generate_feature_level_base_anchors(self, size):\n",
    "        \"\"\"Create K anchors boxes centered on origin for a particular FPN feature level\"\"\"\n",
    "        \n",
    "        anchors = np.zeros((self.n_anchors, 4)) \n",
    "        #scale base size at different scales\n",
    "        anchors[:, 2:] = size * np.tile(self.scales, (2, len(self.ratios))).T\n",
    "        # get different combinations of aspect ratios\n",
    "        areas = anchors[:, 2] * anchors[:, 3]\n",
    "        anchors[:, 2] = np.sqrt(areas / np.repeat(self.ratios, len(self.scales)))\n",
    "        anchors[:, 3] = anchors[:, 2] * np.repeat(self.ratios, len(self.scales))\n",
    "        \n",
    "        # transform from (x_ctr, y_ctr, w, h) -> (x1, y1, x2, y2)\n",
    "        anchors[:, 0::2] -= np.tile(anchors[:, 2] * 0.5, (2, 1)).T\n",
    "        anchors[:, 1::2] -= np.tile(anchors[:, 3] * 0.5, (2, 1)).T\n",
    "        \n",
    "        #self.base_anchors = tf.cast(anchors, dtype=tf.float32)\n",
    "        return anchors\n",
    "    \n",
    "    def shift_and_duplicate(self, anchors, stride):\n",
    "        \"\"\"Generate bounding boxes by duplicating FPN base anchors every s strides\"\"\"\n",
    "        feature_size = int(np.round(self.resolution/stride))\n",
    "\n",
    "        # image_size/stride should equal feature_size (so we could write it for either)\n",
    "        shift_x = (tf.keras.backend.arange(0, feature_size, dtype=tf.float32) + tf.keras.backend.constant(0.5, dtype=tf.float32)) * stride\n",
    "        shift_y = (tf.keras.backend.arange(0, feature_size, dtype=tf.float32) + tf.keras.backend.constant(0.5, dtype=tf.float32)) * stride\n",
    "\n",
    "        # a tensor that supports cartesian indexing\n",
    "        shift_x, tf.meshgrid(shift_x)\n",
    "        shift_y = tf.meshgrid(shift_y)\n",
    "\n",
    "        # make sure of 1-dimensionsal \n",
    "        shift_x = tf.keras.backend.reshape(shift_x, [-1])\n",
    "        shift_y = tf.keras.backend.reshape(shift_y, [-1])\n",
    "        \n",
    "        shifts = tf.keras.backend.stack([shift_x, shift_y, shift_x, shift_y], axis=0)\n",
    "        shifts = tf.keras.backend.transpose(shifts)\n",
    "        \n",
    "        k = tf.keras.backend.shape(shifts)[0]\n",
    "        \n",
    "        anchors = tf.convert_to_tensor(anchors, dtype=tf.float32)\n",
    "        shifts = tf.cast(shifts, dtype=tf.float32)\n",
    "        \n",
    "\n",
    "        shifted_anchors = tf.keras.backend.reshape(anchors, [1, self.n_anchors, 4]) + tf.keras.backend.reshape(shifts, [k, 1, 4])\n",
    "        shifted_anchors = tf.keras.backend.reshape(shifted_anchors, [k * self.n_anchors, 4])\n",
    "        \n",
    "        feature_level_anchors = tf.keras.backend.tile(tf.keras.backend.expand_dims(shifted_anchors, axis=0), (feature_size, 1, 1))\n",
    "        feature_level_anchors = tf.keras.backend.reshape(feature_level_anchors, [(feature_size**2)*self.n_anchors, 4])\n",
    "        \n",
    "        return feature_level_anchors\n",
    "    \n",
    "    def generate_all_anchors(self):\n",
    "        \"\"\"Generate all anchor boxes for every level of the pyramid\"\"\"\n",
    "        self.feature_sizes = [int(np.round(self.resolution/stride)) for stride in self.strides]\n",
    "        \n",
    "        all_anchors = [self.generate_feature_level_base_anchors(size=size) for size in self.sizes]\n",
    "        all_anchors = [self.shift_and_duplicate(layer_anchors, stride) for layer_anchors, stride in zip(all_anchors, self.strides)]\n",
    "        all_anchors = tf.concat(all_anchors, axis=0)\n",
    "\n",
    "        return all_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "anchors = Anchors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# test it for another set of features to make sure it is working\n",
    "p3_anchors = anchors.generate_feature_level_base_anchors(size=anchors.sizes[1])\n",
    "p3_anchors = anchors.shift_and_duplicate(p3_anchors, anchors.strides[1])\n",
    "p3_anchors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#generate all anchors\n",
    "all_anchors = anchors.generate_all_anchors()\n",
    "all_anchors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "all_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 4. Loss\n",
    "The loss is actually regressing the transformations (deltas) from the anchor boxes to the ground truth boxes/annotation. \n",
    "So first we need to functions:\n",
    "* 1. Get target transformations: delta between ground truth boxes (annotations) and anchor boxes\n",
    "* 2.  from predicted transformations/deltas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def compute_gt_delta(anchors, gt_boxes, mean=0.0, std=0.2):\n",
    "    \"\"\"Compute ground-truth transformations from annotations and anchor boxes\"\"\"\n",
    "    anchor_widths  = anchors[:, 2] - anchors[:, 0]\n",
    "    anchor_heights = anchors[:, 3] - anchors[:, 1]\n",
    "\n",
    "    # According to the information provided by a keras-retinanet author, they got marginally better results using\n",
    "    # the following way of bounding box parametrization.\n",
    "    # See https://github.com/fizyr/keras-retinanet/issues/1273#issuecomment-585828825 for more details\n",
    "    targets_dx1 = (gt_boxes[:, 0] - anchors[:, 0]) / anchor_widths\n",
    "    targets_dy1 = (gt_boxes[:, 1] - anchors[:, 1]) / anchor_heights\n",
    "    targets_dx2 = (gt_boxes[:, 2] - anchors[:, 2]) / anchor_widths\n",
    "    targets_dy2 = (gt_boxes[:, 3] - anchors[:, 3]) / anchor_heights\n",
    "    \n",
    "    targets = tf.concat((targets_dx1, targets_dy1, targets_dx2, targets_dy2), axis=0)\n",
    "    targets = targets.T\n",
    "\n",
    "    targets = (targets - mean) / std\n",
    "    return targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def compute_pred_boxes(deltas, anchors, mean=0.0, std=0.2):\n",
    "    \"\"\"Get Predicted Boxes from predicted deltas and anchors\"\"\"\n",
    "    #first dimension is the batch size\n",
    "    width  = anchors[:, :, 2] - anchors[:, :, 0]\n",
    "    height = anchors[:, :, 3] - anchors[:, :, 1]\n",
    "\n",
    "    x1 = anchors[:, :, 0] + (deltas[:, :, 0] * std[0] + mean[0]) * width\n",
    "    y1 = anchors[:, :, 1] + (deltas[:, :, 1] * std[1] + mean[1]) * height\n",
    "    x2 = anchors[:, :, 2] + (deltas[:, :, 2] * std[2] + mean[2]) * width\n",
    "    y2 = anchors[:, :, 3] + (deltas[:, :, 3] * std[3] + mean[3]) * height\n",
    "\n",
    "    pred_boxes = tf.keras.backend.stack([x1, y1, x2, y2], axis=2)\n",
    "\n",
    "    return pred_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class RegressBoxes(tf.keras.layers.Layer):\n",
    "    \"\"\" Keras layer for applying regression values to boxes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean=None, std=None, *args, **kwargs):\n",
    "        \"\"\" Initializer for the RegressBoxes layer.\n",
    "        Args\n",
    "            mean: The mean value of the regression values which was used for normalization.\n",
    "            std: The standard value of the regression values which was used for normalization.\n",
    "        \"\"\"\n",
    "        if mean is None:\n",
    "            mean = np.array([0, 0, 0, 0])\n",
    "        if std is None:\n",
    "            std = np.array([0.2, 0.2, 0.2, 0.2])\n",
    "\n",
    "        if isinstance(mean, (list, tuple)):\n",
    "            mean = np.array(mean)\n",
    "        elif not isinstance(mean, np.ndarray):\n",
    "            raise ValueError('Expected mean to be a np.ndarray, list or tuple. Received: {}'.format(type(mean)))\n",
    "\n",
    "        if isinstance(std, (list, tuple)):\n",
    "            std = np.array(std)\n",
    "        elif not isinstance(std, np.ndarray):\n",
    "            raise ValueError('Expected std to be a np.ndarray, list or tuple. Received: {}'.format(type(std)))\n",
    "\n",
    "        self.mean = mean\n",
    "        self.std  = std\n",
    "        super(RegressBoxes, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        anchors, regression_outputs = inputs\n",
    "        return compute_gt_delta(anchors, regression_outputs, mean=self.mean, std=self.std)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RegressBoxes, self).get_config()\n",
    "        config.update({\n",
    "            'mean': self.mean.tolist(),\n",
    "            'std' : self.std.tolist(),\n",
    "        })\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class ClipBoxes(tf.keras.layers.Layer):\n",
    "    \"\"\" Keras layer to clip box values to lie inside a given shape.\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        image, boxes = inputs\n",
    "        image_shape = tf.shape(image)\n",
    "        _, width, height, _ = tf.unstack(image_shape, axis=0)\n",
    "\n",
    "        x1, y1, x2, y2 = tf.unstack(boxes, axis=-1)\n",
    "        x1 = tf.clip_by_value(x1, 0, width  - 1)\n",
    "        y1 = tf.clip_by_value(y1, 0, height - 1)\n",
    "        x2 = tf.clip_by_value(x2, 0, width  - 1)\n",
    "        y2 = tf.clip_by_value(y2, 0, height - 1)\n",
    "\n",
    "        return tf.stack([x1, y1, x2, y2], axis=2)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def filter_detections(\n",
    "    boxes,\n",
    "    classification,\n",
    "    other                 = [],\n",
    "    class_specific_filter = True,\n",
    "    nms                   = True,\n",
    "    score_threshold       = 0.05,\n",
    "    max_detections        = 300,\n",
    "    nms_threshold         = 0.5\n",
    "):\n",
    "    \"\"\" Filter detections using the boxes and classification values.\n",
    "    Args\n",
    "        boxes                 : Tensor of shape (num_boxes, 4) containing the boxes in (x1, y1, x2, y2) format.\n",
    "        classification        : Tensor of shape (num_boxes, num_classes) containing the classification scores.\n",
    "        other                 : List of tensors of shape (num_boxes, ...) to filter along with the boxes and classification scores.\n",
    "        class_specific_filter : Whether to perform filtering per class, or take the best scoring class and filter those.\n",
    "        nms                   : Flag to enable/disable non maximum suppression.\n",
    "        score_threshold       : Threshold used to prefilter the boxes with.\n",
    "        max_detections        : Maximum number of detections to keep.\n",
    "        nms_threshold         : Threshold for the IoU value to determine when a box should be suppressed.\n",
    "    Returns\n",
    "        A list of [boxes, scores, labels, other[0], other[1], ...].\n",
    "        boxes is shaped (max_detections, 4) and contains the (x1, y1, x2, y2) of the non-suppressed boxes.\n",
    "        scores is shaped (max_detections,) and contains the scores of the predicted class.\n",
    "        labels is shaped (max_detections,) and contains the predicted label.\n",
    "        other[i] is shaped (max_detections, ...) and contains the filtered other[i] data.\n",
    "        In case there are less than max_detections detections, the tensors are padded with -1's.\n",
    "    \"\"\"\n",
    "    def _filter_detections(scores, labels):\n",
    "        # threshold based on score\n",
    "        indices = tf.where(tf.math.greater(scores, score_threshold))\n",
    "\n",
    "        if nms:\n",
    "            filtered_boxes  = tf.gather_nd(boxes, indices)\n",
    "            filtered_scores = tf.gather(scores, indices)[:, 0]\n",
    "\n",
    "            # perform NMS\n",
    "            nms_indices = tf.image.non_max_suppression(filtered_boxes, filtered_scores, max_output_size=max_detections, iou_threshold=nms_threshold)\n",
    "\n",
    "            # filter indices based on NMS\n",
    "            indices = tf.gather(indices, nms_indices)\n",
    "\n",
    "        # add indices to list of all indices\n",
    "        labels = tf.gather_nd(labels, indices)\n",
    "        indices = tf.stack([indices[:, 0], labels], axis=1)\n",
    "\n",
    "        return indices\n",
    "\n",
    "    if class_specific_filter:\n",
    "        all_indices = []\n",
    "        # perform per class filtering\n",
    "        for c in range(int(classification.shape[1])):\n",
    "            scores = classification[:, c]\n",
    "            labels = c * tf.ones((tf.shape(scores)[0],), dtype='int64')\n",
    "            all_indices.append(_filter_detections(scores, labels))\n",
    "\n",
    "        # concatenate indices to single tensor\n",
    "        indices = tf.concatenate(all_indices, axis=0)\n",
    "    else:\n",
    "        scores  = tf.keras.backend.max(classification, axis    = 1)\n",
    "        labels  = tf.math.argmax(classification, axis = 1)\n",
    "        indices = _filter_detections(scores, labels)\n",
    "\n",
    "    # select top k\n",
    "    scores              = tf.gather_nd(classification, indices)\n",
    "    labels              = indices[:, 1]\n",
    "    scores, top_indices = tf.top_k(scores, k=tf.math.minimum(max_detections, tf.shape(scores)[0]))\n",
    "\n",
    "    # filter input using the final set of indices\n",
    "    indices             = tf.gather(indices[:, 0], top_indices)\n",
    "    boxes               = tf.gather(boxes, indices)\n",
    "    labels              = tf.gather(labels, top_indices)\n",
    "    other_              = [tf.gather(o, indices) for o in other]\n",
    "\n",
    "    # zero pad the outputs\n",
    "    pad_size = tf.math.maximum(0, max_detections - tf.shape(scores)[0])\n",
    "    boxes    = tf.pad(boxes, [[0, pad_size], [0, 0]], constant_values=-1)\n",
    "    scores   = tf.pad(scores, [[0, pad_size]], constant_values=-1)\n",
    "    labels   = tf.pad(labels, [[0, pad_size]], constant_values=-1)\n",
    "    labels   = tf.cast(labels, 'int32')\n",
    "    other_   = [tf.pad(o, [[0, pad_size]] + [[0, 0] for _ in range(1, len(o.shape))], constant_values=-1) for o in other_]\n",
    "\n",
    "    # set shapes, since we know what they are\n",
    "    boxes.set_shape([max_detections, 4])\n",
    "    scores.set_shape([max_detections])\n",
    "    labels.set_shape([max_detections])\n",
    "    for o, s in zip(other_, [list(keras.backend.int_shape(o)) for o in other]):\n",
    "        o.set_shape([max_detections] + s[1:])\n",
    "\n",
    "    return [boxes, scores, labels] + other_\n",
    "\n",
    "\n",
    "class FilterDetections(tf.keras.layers.Layer):\n",
    "    \"\"\" Keras layer for filtering detections using score threshold and NMS.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nms                   = True,\n",
    "        class_specific_filter = True,\n",
    "        nms_threshold         = 0.5,\n",
    "        score_threshold       = 0.05,\n",
    "        max_detections        = 300,\n",
    "        parallel_iterations   = 32,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\" Filters detections using score threshold, NMS and selecting the top-k detections.\n",
    "        Args\n",
    "            nms                   : Flag to enable/disable NMS.\n",
    "            class_specific_filter : Whether to perform filtering per class, or take the best scoring class and filter those.\n",
    "            nms_threshold         : Threshold for the IoU value to determine when a box should be suppressed.\n",
    "            score_threshold       : Threshold used to prefilter the boxes with.\n",
    "            max_detections        : Maximum number of detections to keep.\n",
    "            parallel_iterations   : Number of batch items to process in parallel.\n",
    "        \"\"\"\n",
    "        self.nms                   = nms\n",
    "        self.class_specific_filter = class_specific_filter\n",
    "        self.nms_threshold         = nms_threshold\n",
    "        self.score_threshold       = score_threshold\n",
    "        self.max_detections        = max_detections\n",
    "        self.parallel_iterations   = parallel_iterations\n",
    "        super(FilterDetections, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" Constructs the NMS graph.\n",
    "        Args\n",
    "            inputs : List of [boxes, classification, other[0], other[1], ...] tensors.\n",
    "        \"\"\"\n",
    "        boxes          = inputs[0]\n",
    "        classification = inputs[1]\n",
    "        other          = inputs[2:]\n",
    "\n",
    "        # wrap nms with our parameters\n",
    "        def _filter_detections(args):\n",
    "            boxes          = args[0]\n",
    "            classification = args[1]\n",
    "            other          = args[2]\n",
    "\n",
    "            return filter_detections(\n",
    "                boxes,\n",
    "                classification,\n",
    "                other,\n",
    "                nms                   = self.nms,\n",
    "                class_specific_filter = self.class_specific_filter,\n",
    "                score_threshold       = self.score_threshold,\n",
    "                max_detections        = self.max_detections,\n",
    "                nms_threshold         = self.nms_threshold,\n",
    "            )\n",
    "\n",
    "        # call filter_detections on each batch\n",
    "        outputs = tf.map_fn(\n",
    "            _filter_detections,\n",
    "            elems=[boxes, classification, other],\n",
    "            dtype=[tf.keras.backend.floatx(), tf.keras.backend.floatx(), 'int32'] + [o.dtype for o in other],\n",
    "            parallel_iterations=self.parallel_iterations\n",
    "        )\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Computes the output shapes given the input shapes.\n",
    "        Args\n",
    "            input_shape : List of input shapes [boxes, classification, other[0], other[1], ...].\n",
    "        Returns\n",
    "            List of tuples representing the output shapes:\n",
    "            [filtered_boxes.shape, filtered_scores.shape, filtered_labels.shape, filtered_other[0].shape, filtered_other[1].shape, ...]\n",
    "        \"\"\"\n",
    "        return [\n",
    "            (input_shape[0][0], self.max_detections, 4),\n",
    "            (input_shape[1][0], self.max_detections),\n",
    "            (input_shape[1][0], self.max_detections),\n",
    "        ] + [\n",
    "            tuple([input_shape[i][0], self.max_detections] + list(input_shape[i][2:])) for i in range(2, len(input_shape))\n",
    "        ]\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        \"\"\" This is required in Keras when there is more than 1 output.\n",
    "        \"\"\"\n",
    "        return (len(inputs) + 1) * [None]\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\" Gets the configuration of this layer.\n",
    "        Returns\n",
    "            Dictionary containing the parameters of this layer.\n",
    "        \"\"\"\n",
    "        config = super(FilterDetections, self).get_config()\n",
    "        config.update({\n",
    "            'nms'                   : self.nms,\n",
    "            'class_specific_filter' : self.class_specific_filter,\n",
    "            'nms_threshold'         : self.nms_threshold,\n",
    "            'score_threshold'       : self.score_threshold,\n",
    "            'max_detections'        : self.max_detections,\n",
    "            'parallel_iterations'   : self.parallel_iterations,\n",
    "        })\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for ex in train.take(1):\n",
    "    img, bboxes = preprocess(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
