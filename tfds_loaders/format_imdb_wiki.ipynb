{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "aKwi1_4l0wev"
   },
   "source": [
    "# Adding a Dataset of Your Own to TFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "w9nZyRcLhtiX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "wooh61rn2FvF"
   },
   "source": [
    "## IMDB Faces Dataset\n",
    "\n",
    "This is the largest publicly available dataset of face images with gender and age labels for training.\n",
    "\n",
    "Source: https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\n",
    "\n",
    "The IMDb Faces dataset provides a separate .mat file which can be loaded with Matlab containing all the meta information. The format is as follows:  \n",
    "**dob**: date of birth (Matlab serial date number)  \n",
    "**photo_taken**: year when the photo was taken  \n",
    "**full_path**: path to file  \n",
    "**gender**: 0 for female and 1 for male, NaN if unknown  \n",
    "**name**: name of the celebrity  \n",
    "**face_location**: location of the face (bounding box)  \n",
    "**face_score**: detector score (the higher the better). Inf implies that no face was found in the image and the face_location then just returns the entire image  \n",
    "**second_face_score**: detector score of the face with the second highest score. This is useful to ignore images with more than one face. second_face_score is NaN if no second face was detected.  \n",
    "**celeb_names**: list of all celebrity names  \n",
    "**celeb_id**: index of celebrity name  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Next, let's inspect the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "uspGC84pWmjR"
   },
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "sp7bUzZr3ZUQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB:\n",
      " 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n",
      "27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      "54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80\n",
      "81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 imdb.mat \n",
      "\n",
      "\n",
      "Wiki:\n",
      " 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n",
      "27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      "54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80\n",
      "81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 wiki.mat\n"
     ]
    }
   ],
   "source": [
    "# Inspect the directory structure\n",
    "indir = \"C:\\\\Users\\\\nick\\\\tensorflow_datasets\\\\downloads\\\\manual\\\\imdb_wiki\"\n",
    "imdb_crop_file_path = os.path.join(indir, 'imdb_crop')\n",
    "wiki_crop_file_path = os.path.join(indir, 'wiki_crop')\n",
    "imdb_files = os.listdir(imdb_crop_file_path)\n",
    "wiki_files = os.listdir(wiki_crop_file_path)\n",
    "print(\"IMDB:\\n\", textwrap.fill(' '.join(sorted(imdb_files)), 80), '\\n\\n')\n",
    "\n",
    "print(\"Wiki:\\n\", textwrap.fill(' '.join(sorted(wiki_files)), 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "1aPlCn9E2PMj"
   },
   "outputs": [],
   "source": [
    "# Inspect the meta data\n",
    "imdb_mat_file_path = os.path.join(indir, 'imdb_crop', 'imdb.mat')\n",
    "meta_imdb = scipy.io.loadmat(imdb_mat_file_path)\n",
    "\n",
    "imdb_mat_file_path = os.path.join(indir, 'wiki_crop', 'wiki.mat')\n",
    "meta_wiki = scipy.io.loadmat(imdb_mat_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "aFj-jsz-6z-I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Jan 17 11:30:27 2016',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'imdb': array([[(array([[693726, 693726, 693726, ..., 726831, 726831, 726831]]), array([[1968, 1970, 1968, ..., 2011, 2011, 2011]], dtype=uint16), array([[array(['01/nm0000001_rm124825600_1899-5-10_1968.jpg'], dtype='<U43'),\n",
       "         array(['01/nm0000001_rm3343756032_1899-5-10_1970.jpg'], dtype='<U44'),\n",
       "         array(['01/nm0000001_rm577153792_1899-5-10_1968.jpg'], dtype='<U43'),\n",
       "         ...,\n",
       "         array(['08/nm3994408_rm926592512_1989-12-29_2011.jpg'], dtype='<U44'),\n",
       "         array(['08/nm3994408_rm943369728_1989-12-29_2011.jpg'], dtype='<U44'),\n",
       "         array(['08/nm3994408_rm976924160_1989-12-29_2011.jpg'], dtype='<U44')]],\n",
       "       dtype=object), array([[1., 1., 1., ..., 0., 0., 0.]]), array([[array(['Fred Astaire'], dtype='<U12'),\n",
       "         array(['Fred Astaire'], dtype='<U12'),\n",
       "         array(['Fred Astaire'], dtype='<U12'), ...,\n",
       "         array(['Jane Levy'], dtype='<U9'),\n",
       "         array(['Jane Levy'], dtype='<U9'),\n",
       "         array(['Jane Levy'], dtype='<U9')]], dtype=object), array([[array([[1072.926,  161.838, 1214.784,  303.696]]),\n",
       "         array([[477.184, 100.352, 622.592, 245.76 ]]),\n",
       "         array([[114.96964309, 114.96964309, 451.68657236, 451.68657236]]),\n",
       "         ..., array([[  1,   1, 453, 640]], dtype=uint16),\n",
       "         array([[144.75225472, 126.76472288, 305.78804127, 287.80050943]]),\n",
       "         array([[457.524,  41.748, 518.016, 102.24 ]])]], dtype=object), array([[1.45969291, 2.5431976 , 3.45557949, ...,       -inf, 4.45072452,\n",
       "         2.13350269]]), array([[1.11897336, 1.85200773, 2.98566022, ...,        nan,        nan,\n",
       "                nan]]), array([[array([\"'Lee' George Quinones\"], dtype='<U21'),\n",
       "         array([\"'Weird Al' Yankovic\"], dtype='<U19'),\n",
       "         array(['2 Chainz'], dtype='<U8'), ...,\n",
       "         array(['Éric Caravaca'], dtype='<U13'),\n",
       "         array(['Ólafur Darri Ólafsson'], dtype='<U21'),\n",
       "         array(['Óscar Jaenada'], dtype='<U13')]], dtype=object), array([[6488, 6488, 6488, ..., 8410, 8410, 8410]], dtype=uint16))]],\n",
       "       dtype=[('dob', 'O'), ('photo_taken', 'O'), ('full_path', 'O'), ('gender', 'O'), ('name', 'O'), ('face_location', 'O'), ('face_score', 'O'), ('second_face_score', 'O'), ('celeb_names', 'O'), ('celeb_id', 'O')])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "rnPmrXJ9XAkK"
   },
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "zOBtgW6U_VgP"
   },
   "source": [
    "Let's clear up the clutter by going to the metadata's most useful key (imdb) and start exploring all the other keys inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "fgrZJWOA7RVa"
   },
   "outputs": [],
   "source": [
    "root = meta_imdb['imdb'][0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "BqqaBw6Y7tku"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dob', '|O'),\n",
       " ('photo_taken', '|O'),\n",
       " ('full_path', '|O'),\n",
       " ('gender', '|O'),\n",
       " ('name', '|O'),\n",
       " ('face_location', '|O'),\n",
       " ('face_score', '|O'),\n",
       " ('second_face_score', '|O'),\n",
       " ('celeb_names', '|O'),\n",
       " ('celeb_id', '|O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = root.dtype.descr\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "s3WJXw4G2cPk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filepaths: [array(['01/nm0000001_rm124825600_1899-5-10_1968.jpg'], dtype='<U43')\n",
      " array(['01/nm0000001_rm3343756032_1899-5-10_1970.jpg'], dtype='<U44')\n",
      " array(['01/nm0000001_rm577153792_1899-5-10_1968.jpg'], dtype='<U43') ...\n",
      " array(['08/nm3994408_rm926592512_1989-12-29_2011.jpg'], dtype='<U44')\n",
      " array(['08/nm3994408_rm943369728_1989-12-29_2011.jpg'], dtype='<U44')\n",
      " array(['08/nm3994408_rm976924160_1989-12-29_2011.jpg'], dtype='<U44')]\n",
      "\n",
      "Names: [array(['Fred Astaire'], dtype='<U12')\n",
      " array(['Fred Astaire'], dtype='<U12')\n",
      " array(['Fred Astaire'], dtype='<U12') ...\n",
      " array(['Jane Levy'], dtype='<U9') array(['Jane Levy'], dtype='<U9')\n",
      " array(['Jane Levy'], dtype='<U9')]\n",
      "\n",
      "Dates of birth: [693726 693726 693726 ... 726831 726831 726831]\n",
      "\n",
      "Genders: [1. 1. 1. ... 0. 0. 0.]\n",
      "\n",
      "Years when the photos were taken: [1968 1970 1968 ... 2011 2011 2011]\n",
      "\n",
      "Face scores: [1.45969291 2.5431976  3.45557949 ...       -inf 4.45072452 2.13350269]\n",
      "\n",
      "Face locations: [array([[1072.926,  161.838, 1214.784,  303.696]])\n",
      " array([[477.184, 100.352, 622.592, 245.76 ]])\n",
      " array([[114.96964309, 114.96964309, 451.68657236, 451.68657236]]) ...\n",
      " array([[  1,   1, 453, 640]], dtype=uint16)\n",
      " array([[144.75225472, 126.76472288, 305.78804127, 287.80050943]])\n",
      " array([[457.524,  41.748, 518.016, 102.24 ]])]\n",
      "\n",
      "Second face scores: [1.11897336 1.85200773 2.98566022 ...        nan        nan        nan]\n",
      "\n",
      "Celeb IDs: [6488 6488 6488 ... 8410 8410 8410]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Fill in the missing code below.\n",
    "\n",
    "full_path = root[\"full_path\"][0]\n",
    "\n",
    "# Do the same for other attributes\n",
    "names = root[\"name\"][0]\n",
    "dob = root[\"dob\"][0]\n",
    "gender = root[\"gender\"][0]\n",
    "photo_taken = root[\"photo_taken\"][0]\n",
    "face_score = root[\"face_score\"][0]\n",
    "face_locations = root[\"face_location\"][0]\n",
    "second_face_score = root[\"second_face_score\"][0]\n",
    "celeb_names = root[\"celeb_names\"][0]\n",
    "celeb_ids = root[\"celeb_id\"][0]\n",
    "\n",
    "print('Filepaths: {}\\n\\n'\n",
    "      'Names: {}\\n\\n'\n",
    "      'Dates of birth: {}\\n\\n'\n",
    "      'Genders: {}\\n\\n'\n",
    "      'Years when the photos were taken: {}\\n\\n'\n",
    "      'Face scores: {}\\n\\n'\n",
    "      'Face locations: {}\\n\\n'\n",
    "      'Second face scores: {}\\n\\n'\n",
    "      'Celeb IDs: {}\\n\\n'\n",
    "      .format(full_path, names, dob, gender, photo_taken, face_score, face_locations, second_face_score, celeb_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "zjKXJU1yEnMb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celeb names: [array([\"'Lee' George Quinones\"], dtype='<U21')\n",
      " array([\"'Weird Al' Yankovic\"], dtype='<U19')\n",
      " array(['2 Chainz'], dtype='<U8') ...\n",
      " array(['Éric Caravaca'], dtype='<U13')\n",
      " array(['Ólafur Darri Ólafsson'], dtype='<U21')\n",
      " array(['Óscar Jaenada'], dtype='<U13')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Celeb names: {}\\n\\n'.format(celeb_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "TT0un3eFXNW-"
   },
   "source": [
    "Display all the distinct keys and their corresponding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "rYb98AUtC_fA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dob',\n",
       " 'photo_taken',\n",
       " 'full_path',\n",
       " 'gender',\n",
       " 'name',\n",
       " 'face_location',\n",
       " 'face_score',\n",
       " 'second_face_score',\n",
       " 'celeb_names',\n",
       " 'celeb_id']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [x[0] for x in desc]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "xJJ9j56hDvnN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dob': array([693726, 693726, 693726, ..., 726831, 726831, 726831]),\n",
       " 'photo_taken': array([1968, 1970, 1968, ..., 2011, 2011, 2011], dtype=uint16),\n",
       " 'full_path': array([array(['01/nm0000001_rm124825600_1899-5-10_1968.jpg'], dtype='<U43'),\n",
       "        array(['01/nm0000001_rm3343756032_1899-5-10_1970.jpg'], dtype='<U44'),\n",
       "        array(['01/nm0000001_rm577153792_1899-5-10_1968.jpg'], dtype='<U43'),\n",
       "        ...,\n",
       "        array(['08/nm3994408_rm926592512_1989-12-29_2011.jpg'], dtype='<U44'),\n",
       "        array(['08/nm3994408_rm943369728_1989-12-29_2011.jpg'], dtype='<U44'),\n",
       "        array(['08/nm3994408_rm976924160_1989-12-29_2011.jpg'], dtype='<U44')],\n",
       "       dtype=object),\n",
       " 'gender': array([1., 1., 1., ..., 0., 0., 0.]),\n",
       " 'name': array([array(['Fred Astaire'], dtype='<U12'),\n",
       "        array(['Fred Astaire'], dtype='<U12'),\n",
       "        array(['Fred Astaire'], dtype='<U12'), ...,\n",
       "        array(['Jane Levy'], dtype='<U9'),\n",
       "        array(['Jane Levy'], dtype='<U9'),\n",
       "        array(['Jane Levy'], dtype='<U9')], dtype=object),\n",
       " 'face_location': array([array([[1072.926,  161.838, 1214.784,  303.696]]),\n",
       "        array([[477.184, 100.352, 622.592, 245.76 ]]),\n",
       "        array([[114.96964309, 114.96964309, 451.68657236, 451.68657236]]),\n",
       "        ..., array([[  1,   1, 453, 640]], dtype=uint16),\n",
       "        array([[144.75225472, 126.76472288, 305.78804127, 287.80050943]]),\n",
       "        array([[457.524,  41.748, 518.016, 102.24 ]])], dtype=object),\n",
       " 'face_score': array([1.45969291, 2.5431976 , 3.45557949, ...,       -inf, 4.45072452,\n",
       "        2.13350269]),\n",
       " 'second_face_score': array([1.11897336, 1.85200773, 2.98566022, ...,        nan,        nan,\n",
       "               nan]),\n",
       " 'celeb_names': array([array([\"'Lee' George Quinones\"], dtype='<U21'),\n",
       "        array([\"'Weird Al' Yankovic\"], dtype='<U19'),\n",
       "        array(['2 Chainz'], dtype='<U8'), ...,\n",
       "        array(['Éric Caravaca'], dtype='<U13'),\n",
       "        array(['Ólafur Darri Ólafsson'], dtype='<U21'),\n",
       "        array(['Óscar Jaenada'], dtype='<U13')], dtype=object),\n",
       " 'celeb_id': array([6488, 6488, 6488, ..., 8410, 8410, 8410], dtype=uint16)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_values = {key: root[key][0] for key in names}\n",
    "imdb_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Repeat for Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dob': array([723671, 703186, 711677, ..., 720620, 723893, 713846]),\n",
       " 'photo_taken': array([2009, 1964, 2008, ..., 2013, 2011, 2008], dtype=uint16),\n",
       " 'full_path': array([array(['17/10000217_1981-05-05_2009.jpg'], dtype='<U31'),\n",
       "        array(['48/10000548_1925-04-04_1964.jpg'], dtype='<U31'),\n",
       "        array(['12/100012_1948-07-03_2008.jpg'], dtype='<U29'), ...,\n",
       "        array(['09/9998109_1972-12-27_2013.jpg'], dtype='<U30'),\n",
       "        array(['00/9999400_1981-12-13_2011.jpg'], dtype='<U30'),\n",
       "        array(['80/999980_1954-06-11_2008.jpg'], dtype='<U29')],\n",
       "       dtype=object),\n",
       " 'gender': array([1., 1., 1., ..., 1., 1., 0.]),\n",
       " 'name': array([array(['Sami Jauhojärvi'], dtype='<U15'),\n",
       "        array(['Dettmar Cramer'], dtype='<U14'),\n",
       "        array(['Marc Okrand'], dtype='<U11'), ...,\n",
       "        array(['Michael Wiesinger'], dtype='<U17'),\n",
       "        array(['Johann Grugger'], dtype='<U14'),\n",
       "        array(['Greta Van Susteren'], dtype='<U18')], dtype=object),\n",
       " 'face_location': array([array([[111.29109473, 111.29109473, 252.66993082, 252.66993082]]),\n",
       "        array([[252.4833023 , 126.68165115, 354.53192596, 228.73027481]]),\n",
       "        array([[113.52, 169.84, 366.08, 422.4 ]]), ...,\n",
       "        array([[169.88839786,  74.31669472, 235.2534231 , 139.68171997]]),\n",
       "        array([[1, 1, 1, 1]], dtype=uint8),\n",
       "        array([[ 92.72633235,  62.0435549 , 230.12083087, 199.43805342]])],\n",
       "       dtype=object),\n",
       " 'face_score': array([4.30096239, 2.6456395 , 4.32932883, ..., 3.49430317,       -inf,\n",
       "        5.48691655]),\n",
       " 'second_face_score': array([       nan, 1.94924791,        nan, ...,        nan,        nan,\n",
       "               nan])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = meta_wiki['wiki'][0, 0]\n",
    "desc = root.dtype.descr\n",
    "names = [x[0] for x in desc]\n",
    "wiki_values = {key: root[key][0] for key in names}\n",
    "wiki_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "lYob5mjgXpuy"
   },
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "3YRjp2gpXbRA"
   },
   "source": [
    "Pop out the celeb names as they are not relevant for creating the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "VRi5bcqnFBua"
   },
   "outputs": [],
   "source": [
    "# del values['celeb_names']\n",
    "# names.pop(names.index('celeb_names'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "V2uhpASzXhuy"
   },
   "source": [
    "Let's see how many values are present in each key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "4Zu_L_QFEPEm"
   },
   "outputs": [],
   "source": [
    "# for key, value in values.items():\n",
    "#     print(key, len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "uJUvw-MBXuKb"
   },
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "2_uZu2ZQ_169"
   },
   "source": [
    "Now, let's try examining one example from the dataset. To do this, let's load all the attributes that we've extracted just now into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "x-O0pLwWAREq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm124825600_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[1072.926, 161.838, 1214.7839999999999, 303.6...</td>\n",
       "      <td>1.459693</td>\n",
       "      <td>1.118973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693726</td>\n",
       "      <td>1970</td>\n",
       "      <td>[01/nm0000001_rm3343756032_1899-5-10_1970.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[477.184, 100.352, 622.592, 245.76]]</td>\n",
       "      <td>2.543198</td>\n",
       "      <td>1.852008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm577153792_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[114.96964308962852, 114.96964308962852, 451....</td>\n",
       "      <td>3.455579</td>\n",
       "      <td>2.985660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm946909184_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[622.8855056426588, 424.21750383700805, 844.3...</td>\n",
       "      <td>1.872117</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm980463616_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[1013.8590023603723, 233.8820422075853, 1201....</td>\n",
       "      <td>1.158766</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                                       full_path  \\\n",
       "0  693726         1968   [01/nm0000001_rm124825600_1899-5-10_1968.jpg]   \n",
       "1  693726         1970  [01/nm0000001_rm3343756032_1899-5-10_1970.jpg]   \n",
       "2  693726         1968   [01/nm0000001_rm577153792_1899-5-10_1968.jpg]   \n",
       "3  693726         1968   [01/nm0000001_rm946909184_1899-5-10_1968.jpg]   \n",
       "4  693726         1968   [01/nm0000001_rm980463616_1899-5-10_1968.jpg]   \n",
       "\n",
       "   gender            name                                      face_location  \\\n",
       "0     1.0  [Fred Astaire]  [[1072.926, 161.838, 1214.7839999999999, 303.6...   \n",
       "1     1.0  [Fred Astaire]              [[477.184, 100.352, 622.592, 245.76]]   \n",
       "2     1.0  [Fred Astaire]  [[114.96964308962852, 114.96964308962852, 451....   \n",
       "3     1.0  [Fred Astaire]  [[622.8855056426588, 424.21750383700805, 844.3...   \n",
       "4     1.0  [Fred Astaire]  [[1013.8590023603723, 233.8820422075853, 1201....   \n",
       "\n",
       "   face_score  second_face_score  \n",
       "0    1.459693           1.118973  \n",
       "1    2.543198           1.852008  \n",
       "2    3.455579           2.985660  \n",
       "3    1.872117                NaN  \n",
       "4    1.158766                NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb = pd.DataFrame(imdb_values, columns=names)\n",
    "df_wiki = pd.DataFrame(wiki_values, columns=names)\n",
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310525</th>\n",
       "      <td>720083</td>\n",
       "      <td>2010</td>\n",
       "      <td>[41/nm0342241_rm1022358272_1971-7-9_2010.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[294.00498926749765, 168.6457081528558, 668.5...</td>\n",
       "      <td>4.548166</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310526</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm1557565952_1971-7-9_1994.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[1, 1, 298, 450]]</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310527</th>\n",
       "      <td>720083</td>\n",
       "      <td>2003</td>\n",
       "      <td>[41/nm0342241_rm1724627200_1971-7-9_2003.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[911.7226839189836, 287.91284351739483, 1143....</td>\n",
       "      <td>5.092657</td>\n",
       "      <td>4.542781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310528</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm1936167936_1971-7-9_1994.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[70.32421938479912, 64.50386776939919, 122.22...</td>\n",
       "      <td>3.343579</td>\n",
       "      <td>2.611601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310529</th>\n",
       "      <td>720083</td>\n",
       "      <td>2010</td>\n",
       "      <td>[41/nm0342241_rm2388233728_1971-7-9_2010.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[575.488, 116.736, 720.896, 262.144]]</td>\n",
       "      <td>2.858895</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310530</th>\n",
       "      <td>720083</td>\n",
       "      <td>2011</td>\n",
       "      <td>[41/nm0342241_rm2647042816_1971-7-9_2011.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[383.0868125430132, 118.42671155169637, 448.4...</td>\n",
       "      <td>4.144725</td>\n",
       "      <td>2.727795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310531</th>\n",
       "      <td>720083</td>\n",
       "      <td>2011</td>\n",
       "      <td>[41/nm0342241_rm2680597248_1971-7-9_2011.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[323.9483690955212, 89.9443776815231, 423.435...</td>\n",
       "      <td>4.239688</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310532</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm3477179136_1971-7-9_1994.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[43.29, 53.946000000000005, 138.5280000000000...</td>\n",
       "      <td>2.287371</td>\n",
       "      <td>1.382159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310533</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm3706427392_1971-7-9_1994.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[72.32877735181498, 72.32877735181498, 286.71...</td>\n",
       "      <td>4.628412</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310534</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm3792738304_1971-7-9_1994.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[159.29999999999998, 101.69999999999999, 288....</td>\n",
       "      <td>4.098548</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310535</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm4128282624_1971-7-9_1994.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[128.1250527756009, 43.0283509252003, 170.193...</td>\n",
       "      <td>2.541669</td>\n",
       "      <td>1.700773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310536</th>\n",
       "      <td>720083</td>\n",
       "      <td>2003</td>\n",
       "      <td>[41/nm0342241_rm416004352_1971-7-9_2003.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[671.7425608596343, 711.1391820866717, 1024.3...</td>\n",
       "      <td>2.962549</td>\n",
       "      <td>2.615386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310537</th>\n",
       "      <td>720083</td>\n",
       "      <td>2010</td>\n",
       "      <td>[41/nm0342241_rm4241457664_1971-7-9_2010.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[40.53708192757677, 80.53016385515353, 219.96...</td>\n",
       "      <td>4.443826</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310538</th>\n",
       "      <td>720083</td>\n",
       "      <td>2001</td>\n",
       "      <td>[41/nm0342241_rm443860992_1971-7-9_2001.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[1, 1, 2088, 3000]]</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310539</th>\n",
       "      <td>720083</td>\n",
       "      <td>2003</td>\n",
       "      <td>[41/nm0342241_rm483113216_1971-7-9_2003.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[571.7543840785293, 222.5500841594307, 735.16...</td>\n",
       "      <td>3.885471</td>\n",
       "      <td>3.381501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310540</th>\n",
       "      <td>720083</td>\n",
       "      <td>2003</td>\n",
       "      <td>[41/nm0342241_rm558996224_1971-7-9_2003.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[50.71985362501876, 67.43980483335834, 200.63...</td>\n",
       "      <td>4.274568</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310541</th>\n",
       "      <td>720083</td>\n",
       "      <td>2003</td>\n",
       "      <td>[41/nm0342241_rm575773440_1971-7-9_2003.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[150.39987441065605, 63.94571609681602, 201.7...</td>\n",
       "      <td>4.200974</td>\n",
       "      <td>3.561390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310542</th>\n",
       "      <td>720083</td>\n",
       "      <td>1984</td>\n",
       "      <td>[41/nm0342241_rm696109056_1971-7-9_1984.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[860.4282331567886, 689.0883865254309, 1165.1...</td>\n",
       "      <td>3.180328</td>\n",
       "      <td>2.096533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310543</th>\n",
       "      <td>720083</td>\n",
       "      <td>2009</td>\n",
       "      <td>[41/nm0342241_rm820224256_1971-7-9_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[41, 153, 112, 224]]</td>\n",
       "      <td>1.395016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310544</th>\n",
       "      <td>720083</td>\n",
       "      <td>2009</td>\n",
       "      <td>[41/nm0342241_rm837001472_1971-7-9_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[1, 1, 533, 800]]</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310545</th>\n",
       "      <td>720083</td>\n",
       "      <td>2010</td>\n",
       "      <td>[41/nm0342241_rm837808896_1971-7-9_2010.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[253.5, 229.5, 360.0, 336.0]]</td>\n",
       "      <td>1.779573</td>\n",
       "      <td>1.536040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310546</th>\n",
       "      <td>720083</td>\n",
       "      <td>2009</td>\n",
       "      <td>[41/nm0342241_rm853778688_1971-7-9_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Scott Grimes]</td>\n",
       "      <td>[[146.50879038499818, 170.76025544916453, 363....</td>\n",
       "      <td>2.926798</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dob  photo_taken                                      full_path  \\\n",
       "310525  720083         2010  [41/nm0342241_rm1022358272_1971-7-9_2010.jpg]   \n",
       "310526  720083         1994  [41/nm0342241_rm1557565952_1971-7-9_1994.jpg]   \n",
       "310527  720083         2003  [41/nm0342241_rm1724627200_1971-7-9_2003.jpg]   \n",
       "310528  720083         1994  [41/nm0342241_rm1936167936_1971-7-9_1994.jpg]   \n",
       "310529  720083         2010  [41/nm0342241_rm2388233728_1971-7-9_2010.jpg]   \n",
       "310530  720083         2011  [41/nm0342241_rm2647042816_1971-7-9_2011.jpg]   \n",
       "310531  720083         2011  [41/nm0342241_rm2680597248_1971-7-9_2011.jpg]   \n",
       "310532  720083         1994  [41/nm0342241_rm3477179136_1971-7-9_1994.jpg]   \n",
       "310533  720083         1994  [41/nm0342241_rm3706427392_1971-7-9_1994.jpg]   \n",
       "310534  720083         1994  [41/nm0342241_rm3792738304_1971-7-9_1994.jpg]   \n",
       "310535  720083         1994  [41/nm0342241_rm4128282624_1971-7-9_1994.jpg]   \n",
       "310536  720083         2003   [41/nm0342241_rm416004352_1971-7-9_2003.jpg]   \n",
       "310537  720083         2010  [41/nm0342241_rm4241457664_1971-7-9_2010.jpg]   \n",
       "310538  720083         2001   [41/nm0342241_rm443860992_1971-7-9_2001.jpg]   \n",
       "310539  720083         2003   [41/nm0342241_rm483113216_1971-7-9_2003.jpg]   \n",
       "310540  720083         2003   [41/nm0342241_rm558996224_1971-7-9_2003.jpg]   \n",
       "310541  720083         2003   [41/nm0342241_rm575773440_1971-7-9_2003.jpg]   \n",
       "310542  720083         1984   [41/nm0342241_rm696109056_1971-7-9_1984.jpg]   \n",
       "310543  720083         2009   [41/nm0342241_rm820224256_1971-7-9_2009.jpg]   \n",
       "310544  720083         2009   [41/nm0342241_rm837001472_1971-7-9_2009.jpg]   \n",
       "310545  720083         2010   [41/nm0342241_rm837808896_1971-7-9_2010.jpg]   \n",
       "310546  720083         2009   [41/nm0342241_rm853778688_1971-7-9_2009.jpg]   \n",
       "\n",
       "        gender            name  \\\n",
       "310525     1.0  [Scott Grimes]   \n",
       "310526     1.0  [Scott Grimes]   \n",
       "310527     1.0  [Scott Grimes]   \n",
       "310528     1.0  [Scott Grimes]   \n",
       "310529     1.0  [Scott Grimes]   \n",
       "310530     1.0  [Scott Grimes]   \n",
       "310531     1.0  [Scott Grimes]   \n",
       "310532     1.0  [Scott Grimes]   \n",
       "310533     1.0  [Scott Grimes]   \n",
       "310534     1.0  [Scott Grimes]   \n",
       "310535     1.0  [Scott Grimes]   \n",
       "310536     1.0  [Scott Grimes]   \n",
       "310537     1.0  [Scott Grimes]   \n",
       "310538     1.0  [Scott Grimes]   \n",
       "310539     1.0  [Scott Grimes]   \n",
       "310540     1.0  [Scott Grimes]   \n",
       "310541     1.0  [Scott Grimes]   \n",
       "310542     1.0  [Scott Grimes]   \n",
       "310543     1.0  [Scott Grimes]   \n",
       "310544     1.0  [Scott Grimes]   \n",
       "310545     1.0  [Scott Grimes]   \n",
       "310546     1.0  [Scott Grimes]   \n",
       "\n",
       "                                            face_location  face_score  \\\n",
       "310525  [[294.00498926749765, 168.6457081528558, 668.5...    4.548166   \n",
       "310526                                 [[1, 1, 298, 450]]        -inf   \n",
       "310527  [[911.7226839189836, 287.91284351739483, 1143....    5.092657   \n",
       "310528  [[70.32421938479912, 64.50386776939919, 122.22...    3.343579   \n",
       "310529             [[575.488, 116.736, 720.896, 262.144]]    2.858895   \n",
       "310530  [[383.0868125430132, 118.42671155169637, 448.4...    4.144725   \n",
       "310531  [[323.9483690955212, 89.9443776815231, 423.435...    4.239688   \n",
       "310532  [[43.29, 53.946000000000005, 138.5280000000000...    2.287371   \n",
       "310533  [[72.32877735181498, 72.32877735181498, 286.71...    4.628412   \n",
       "310534  [[159.29999999999998, 101.69999999999999, 288....    4.098548   \n",
       "310535  [[128.1250527756009, 43.0283509252003, 170.193...    2.541669   \n",
       "310536  [[671.7425608596343, 711.1391820866717, 1024.3...    2.962549   \n",
       "310537  [[40.53708192757677, 80.53016385515353, 219.96...    4.443826   \n",
       "310538                               [[1, 1, 2088, 3000]]        -inf   \n",
       "310539  [[571.7543840785293, 222.5500841594307, 735.16...    3.885471   \n",
       "310540  [[50.71985362501876, 67.43980483335834, 200.63...    4.274568   \n",
       "310541  [[150.39987441065605, 63.94571609681602, 201.7...    4.200974   \n",
       "310542  [[860.4282331567886, 689.0883865254309, 1165.1...    3.180328   \n",
       "310543                              [[41, 153, 112, 224]]    1.395016   \n",
       "310544                                 [[1, 1, 533, 800]]        -inf   \n",
       "310545                     [[253.5, 229.5, 360.0, 336.0]]    1.779573   \n",
       "310546  [[146.50879038499818, 170.76025544916453, 363....    2.926798   \n",
       "\n",
       "        second_face_score  \n",
       "310525                NaN  \n",
       "310526                NaN  \n",
       "310527           4.542781  \n",
       "310528           2.611601  \n",
       "310529                NaN  \n",
       "310530           2.727795  \n",
       "310531                NaN  \n",
       "310532           1.382159  \n",
       "310533                NaN  \n",
       "310534                NaN  \n",
       "310535           1.700773  \n",
       "310536           2.615386  \n",
       "310537                NaN  \n",
       "310538                NaN  \n",
       "310539           3.381501  \n",
       "310540                NaN  \n",
       "310541           3.561390  \n",
       "310542           2.096533  \n",
       "310543                NaN  \n",
       "310544                NaN  \n",
       "310545           1.536040  \n",
       "310546                NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb[df_imdb['name']=='Scott Grimes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Clean nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    " # Filter dataframe by only having the rows with face_scores > 1.0\n",
    "df_imdb = df_imdb[df_imdb['face_score']>1.0]\n",
    "df_wiki = df_wiki[df_wiki['face_score']>1.0]\n",
    "\n",
    "# Remove any records that contain Nulls/NaNs by checking for NaN with .isna()\n",
    "df_imdb = df_imdb[~df_imdb['gender'].isna()].reset_index(drop=True)\n",
    "df_wiki = df_wiki[~df_wiki['gender'].isna()].reset_index(drop=True)\n",
    "#df = df[~df['second_face_scores'].isna()]\n",
    "\n",
    "# Cast genders to integers so that mapping can take place\n",
    "df_imdb.gender = df_imdb.gender.astype(int)\n",
    "df_wiki.gender = df_wiki.gender.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Get the age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ages=[]\n",
    "for dob, photo_taken in zip(df_imdb.dob, df_imdb.photo_taken):\n",
    "    ages.append(int(photo_taken) - int(datetime.fromordinal(int(dob)).year))\n",
    "df_imdb['age'] = ages\n",
    "\n",
    "ages=[]\n",
    "for dob, photo_taken in zip(df_wiki.dob, df_wiki.photo_taken):\n",
    "    ages.append(int(photo_taken) - int(datetime.fromordinal(int(dob)).year))\n",
    "df_wiki['age'] = ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Break out the image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#IMDB\n",
    "maindir='imdb_crop'\n",
    "subdirs=[]\n",
    "filenames=[]\n",
    "for full_path in df_imdb.full_path:\n",
    "    subdir, filename = full_path[0].split('/')\n",
    "    subdirs.append(subdir)\n",
    "    filenames.append(filename)\n",
    "    \n",
    "df_imdb['maindir'] = maindir\n",
    "df_imdb['subdir'] = subdirs\n",
    "df_imdb['filename'] = filenames\n",
    "\n",
    "#make sure they're strings\n",
    "df_imdb['maindir'] = df_imdb['maindir'].astype(str)\n",
    "df_imdb['subdir'] = df_imdb['subdir'].astype(str)\n",
    "df_imdb['filename'] = df_imdb['filename'].astype(str)\n",
    "    \n",
    "#Wiki\n",
    "maindir='wiki_crop'\n",
    "subdirs=[]\n",
    "filenames=[]\n",
    "for full_path in df_wiki.full_path:\n",
    "    subdir, filename = full_path[0].split('/')\n",
    "    subdirs.append(subdir)\n",
    "    filenames.append(filename)\n",
    "    \n",
    "df_wiki['maindir'] = maindir\n",
    "df_wiki['subdir'] = subdirs\n",
    "df_wiki['filename'] = filenames\n",
    "\n",
    "#make sure they're strings\n",
    "df_wiki['maindir'] = df_wiki['maindir'].astype(str)\n",
    "df_wiki['subdir'] = df_wiki['subdir'].astype(str)\n",
    "df_wiki['filename'] = df_wiki['filename'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Convert names to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_imdb['name'] = [x[0] for x in df_imdb['name']]\n",
    "df_wiki['name'] = [x[0] for x in df_wiki['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "      <th>age</th>\n",
       "      <th>maindir</th>\n",
       "      <th>subdir</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm124825600_1899-5-10_1968.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>[[1072.926, 161.838, 1214.7839999999999, 303.6...</td>\n",
       "      <td>1.459693</td>\n",
       "      <td>1.118973</td>\n",
       "      <td>68</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>01</td>\n",
       "      <td>nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693726</td>\n",
       "      <td>1970</td>\n",
       "      <td>[01/nm0000001_rm3343756032_1899-5-10_1970.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>[[477.184, 100.352, 622.592, 245.76]]</td>\n",
       "      <td>2.543198</td>\n",
       "      <td>1.852008</td>\n",
       "      <td>70</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>01</td>\n",
       "      <td>nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm577153792_1899-5-10_1968.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>[[114.96964308962852, 114.96964308962852, 451....</td>\n",
       "      <td>3.455579</td>\n",
       "      <td>2.985660</td>\n",
       "      <td>68</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>01</td>\n",
       "      <td>nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm946909184_1899-5-10_1968.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>[[622.8855056426588, 424.21750383700805, 844.3...</td>\n",
       "      <td>1.872117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>01</td>\n",
       "      <td>nm0000001_rm946909184_1899-5-10_1968.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm980463616_1899-5-10_1968.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>[[1013.8590023603723, 233.8820422075853, 1201....</td>\n",
       "      <td>1.158766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>01</td>\n",
       "      <td>nm0000001_rm980463616_1899-5-10_1968.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                                       full_path  \\\n",
       "0  693726         1968   [01/nm0000001_rm124825600_1899-5-10_1968.jpg]   \n",
       "1  693726         1970  [01/nm0000001_rm3343756032_1899-5-10_1970.jpg]   \n",
       "2  693726         1968   [01/nm0000001_rm577153792_1899-5-10_1968.jpg]   \n",
       "3  693726         1968   [01/nm0000001_rm946909184_1899-5-10_1968.jpg]   \n",
       "4  693726         1968   [01/nm0000001_rm980463616_1899-5-10_1968.jpg]   \n",
       "\n",
       "   gender          name                                      face_location  \\\n",
       "0       1  Fred Astaire  [[1072.926, 161.838, 1214.7839999999999, 303.6...   \n",
       "1       1  Fred Astaire              [[477.184, 100.352, 622.592, 245.76]]   \n",
       "2       1  Fred Astaire  [[114.96964308962852, 114.96964308962852, 451....   \n",
       "3       1  Fred Astaire  [[622.8855056426588, 424.21750383700805, 844.3...   \n",
       "4       1  Fred Astaire  [[1013.8590023603723, 233.8820422075853, 1201....   \n",
       "\n",
       "   face_score  second_face_score  age    maindir subdir  \\\n",
       "0    1.459693           1.118973   68  imdb_crop     01   \n",
       "1    2.543198           1.852008   70  imdb_crop     01   \n",
       "2    3.455579           2.985660   68  imdb_crop     01   \n",
       "3    1.872117                NaN   68  imdb_crop     01   \n",
       "4    1.158766                NaN   68  imdb_crop     01   \n",
       "\n",
       "                                    filename  \n",
       "0   nm0000001_rm124825600_1899-5-10_1968.jpg  \n",
       "1  nm0000001_rm3343756032_1899-5-10_1970.jpg  \n",
       "2   nm0000001_rm577153792_1899-5-10_1968.jpg  \n",
       "3   nm0000001_rm946909184_1899-5-10_1968.jpg  \n",
       "4   nm0000001_rm980463616_1899-5-10_1968.jpg  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "      <th>age</th>\n",
       "      <th>maindir</th>\n",
       "      <th>subdir</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260030</th>\n",
       "      <td>720083</td>\n",
       "      <td>2010</td>\n",
       "      <td>[41/nm0342241_rm1022358272_1971-7-9_2010.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[294.00498926749765, 168.6457081528558, 668.5...</td>\n",
       "      <td>4.548166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm1022358272_1971-7-9_2010.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260031</th>\n",
       "      <td>720083</td>\n",
       "      <td>2003</td>\n",
       "      <td>[41/nm0342241_rm1724627200_1971-7-9_2003.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[911.7226839189836, 287.91284351739483, 1143....</td>\n",
       "      <td>5.092657</td>\n",
       "      <td>4.542781</td>\n",
       "      <td>31</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm1724627200_1971-7-9_2003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260032</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm1936167936_1971-7-9_1994.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[70.32421938479912, 64.50386776939919, 122.22...</td>\n",
       "      <td>3.343579</td>\n",
       "      <td>2.611601</td>\n",
       "      <td>22</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm1936167936_1971-7-9_1994.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260033</th>\n",
       "      <td>720083</td>\n",
       "      <td>2010</td>\n",
       "      <td>[41/nm0342241_rm2388233728_1971-7-9_2010.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[575.488, 116.736, 720.896, 262.144]]</td>\n",
       "      <td>2.858895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm2388233728_1971-7-9_2010.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260034</th>\n",
       "      <td>720083</td>\n",
       "      <td>2011</td>\n",
       "      <td>[41/nm0342241_rm2647042816_1971-7-9_2011.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[383.0868125430132, 118.42671155169637, 448.4...</td>\n",
       "      <td>4.144725</td>\n",
       "      <td>2.727795</td>\n",
       "      <td>39</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm2647042816_1971-7-9_2011.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260035</th>\n",
       "      <td>720083</td>\n",
       "      <td>2011</td>\n",
       "      <td>[41/nm0342241_rm2680597248_1971-7-9_2011.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[323.9483690955212, 89.9443776815231, 423.435...</td>\n",
       "      <td>4.239688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm2680597248_1971-7-9_2011.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260036</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm3477179136_1971-7-9_1994.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[43.29, 53.946000000000005, 138.5280000000000...</td>\n",
       "      <td>2.287371</td>\n",
       "      <td>1.382159</td>\n",
       "      <td>22</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm3477179136_1971-7-9_1994.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260037</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm3706427392_1971-7-9_1994.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[72.32877735181498, 72.32877735181498, 286.71...</td>\n",
       "      <td>4.628412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm3706427392_1971-7-9_1994.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260038</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm3792738304_1971-7-9_1994.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[159.29999999999998, 101.69999999999999, 288....</td>\n",
       "      <td>4.098548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm3792738304_1971-7-9_1994.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260039</th>\n",
       "      <td>720083</td>\n",
       "      <td>1994</td>\n",
       "      <td>[41/nm0342241_rm4128282624_1971-7-9_1994.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[128.1250527756009, 43.0283509252003, 170.193...</td>\n",
       "      <td>2.541669</td>\n",
       "      <td>1.700773</td>\n",
       "      <td>22</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm4128282624_1971-7-9_1994.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260040</th>\n",
       "      <td>720083</td>\n",
       "      <td>2003</td>\n",
       "      <td>[41/nm0342241_rm416004352_1971-7-9_2003.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[671.7425608596343, 711.1391820866717, 1024.3...</td>\n",
       "      <td>2.962549</td>\n",
       "      <td>2.615386</td>\n",
       "      <td>31</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm416004352_1971-7-9_2003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260041</th>\n",
       "      <td>720083</td>\n",
       "      <td>2010</td>\n",
       "      <td>[41/nm0342241_rm4241457664_1971-7-9_2010.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[40.53708192757677, 80.53016385515353, 219.96...</td>\n",
       "      <td>4.443826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm4241457664_1971-7-9_2010.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260042</th>\n",
       "      <td>720083</td>\n",
       "      <td>2003</td>\n",
       "      <td>[41/nm0342241_rm483113216_1971-7-9_2003.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[571.7543840785293, 222.5500841594307, 735.16...</td>\n",
       "      <td>3.885471</td>\n",
       "      <td>3.381501</td>\n",
       "      <td>31</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm483113216_1971-7-9_2003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260043</th>\n",
       "      <td>720083</td>\n",
       "      <td>2003</td>\n",
       "      <td>[41/nm0342241_rm558996224_1971-7-9_2003.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[50.71985362501876, 67.43980483335834, 200.63...</td>\n",
       "      <td>4.274568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm558996224_1971-7-9_2003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260044</th>\n",
       "      <td>720083</td>\n",
       "      <td>2003</td>\n",
       "      <td>[41/nm0342241_rm575773440_1971-7-9_2003.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[150.39987441065605, 63.94571609681602, 201.7...</td>\n",
       "      <td>4.200974</td>\n",
       "      <td>3.561390</td>\n",
       "      <td>31</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm575773440_1971-7-9_2003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260045</th>\n",
       "      <td>720083</td>\n",
       "      <td>1984</td>\n",
       "      <td>[41/nm0342241_rm696109056_1971-7-9_1984.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[860.4282331567886, 689.0883865254309, 1165.1...</td>\n",
       "      <td>3.180328</td>\n",
       "      <td>2.096533</td>\n",
       "      <td>12</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm696109056_1971-7-9_1984.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260046</th>\n",
       "      <td>720083</td>\n",
       "      <td>2009</td>\n",
       "      <td>[41/nm0342241_rm820224256_1971-7-9_2009.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[41, 153, 112, 224]]</td>\n",
       "      <td>1.395016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm820224256_1971-7-9_2009.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260047</th>\n",
       "      <td>720083</td>\n",
       "      <td>2010</td>\n",
       "      <td>[41/nm0342241_rm837808896_1971-7-9_2010.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[253.5, 229.5, 360.0, 336.0]]</td>\n",
       "      <td>1.779573</td>\n",
       "      <td>1.536040</td>\n",
       "      <td>38</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm837808896_1971-7-9_2010.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260048</th>\n",
       "      <td>720083</td>\n",
       "      <td>2009</td>\n",
       "      <td>[41/nm0342241_rm853778688_1971-7-9_2009.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>Scott Grimes</td>\n",
       "      <td>[[146.50879038499818, 170.76025544916453, 363....</td>\n",
       "      <td>2.926798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>41</td>\n",
       "      <td>nm0342241_rm853778688_1971-7-9_2009.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dob  photo_taken                                      full_path  \\\n",
       "260030  720083         2010  [41/nm0342241_rm1022358272_1971-7-9_2010.jpg]   \n",
       "260031  720083         2003  [41/nm0342241_rm1724627200_1971-7-9_2003.jpg]   \n",
       "260032  720083         1994  [41/nm0342241_rm1936167936_1971-7-9_1994.jpg]   \n",
       "260033  720083         2010  [41/nm0342241_rm2388233728_1971-7-9_2010.jpg]   \n",
       "260034  720083         2011  [41/nm0342241_rm2647042816_1971-7-9_2011.jpg]   \n",
       "260035  720083         2011  [41/nm0342241_rm2680597248_1971-7-9_2011.jpg]   \n",
       "260036  720083         1994  [41/nm0342241_rm3477179136_1971-7-9_1994.jpg]   \n",
       "260037  720083         1994  [41/nm0342241_rm3706427392_1971-7-9_1994.jpg]   \n",
       "260038  720083         1994  [41/nm0342241_rm3792738304_1971-7-9_1994.jpg]   \n",
       "260039  720083         1994  [41/nm0342241_rm4128282624_1971-7-9_1994.jpg]   \n",
       "260040  720083         2003   [41/nm0342241_rm416004352_1971-7-9_2003.jpg]   \n",
       "260041  720083         2010  [41/nm0342241_rm4241457664_1971-7-9_2010.jpg]   \n",
       "260042  720083         2003   [41/nm0342241_rm483113216_1971-7-9_2003.jpg]   \n",
       "260043  720083         2003   [41/nm0342241_rm558996224_1971-7-9_2003.jpg]   \n",
       "260044  720083         2003   [41/nm0342241_rm575773440_1971-7-9_2003.jpg]   \n",
       "260045  720083         1984   [41/nm0342241_rm696109056_1971-7-9_1984.jpg]   \n",
       "260046  720083         2009   [41/nm0342241_rm820224256_1971-7-9_2009.jpg]   \n",
       "260047  720083         2010   [41/nm0342241_rm837808896_1971-7-9_2010.jpg]   \n",
       "260048  720083         2009   [41/nm0342241_rm853778688_1971-7-9_2009.jpg]   \n",
       "\n",
       "        gender          name  \\\n",
       "260030       1  Scott Grimes   \n",
       "260031       1  Scott Grimes   \n",
       "260032       1  Scott Grimes   \n",
       "260033       1  Scott Grimes   \n",
       "260034       1  Scott Grimes   \n",
       "260035       1  Scott Grimes   \n",
       "260036       1  Scott Grimes   \n",
       "260037       1  Scott Grimes   \n",
       "260038       1  Scott Grimes   \n",
       "260039       1  Scott Grimes   \n",
       "260040       1  Scott Grimes   \n",
       "260041       1  Scott Grimes   \n",
       "260042       1  Scott Grimes   \n",
       "260043       1  Scott Grimes   \n",
       "260044       1  Scott Grimes   \n",
       "260045       1  Scott Grimes   \n",
       "260046       1  Scott Grimes   \n",
       "260047       1  Scott Grimes   \n",
       "260048       1  Scott Grimes   \n",
       "\n",
       "                                            face_location  face_score  \\\n",
       "260030  [[294.00498926749765, 168.6457081528558, 668.5...    4.548166   \n",
       "260031  [[911.7226839189836, 287.91284351739483, 1143....    5.092657   \n",
       "260032  [[70.32421938479912, 64.50386776939919, 122.22...    3.343579   \n",
       "260033             [[575.488, 116.736, 720.896, 262.144]]    2.858895   \n",
       "260034  [[383.0868125430132, 118.42671155169637, 448.4...    4.144725   \n",
       "260035  [[323.9483690955212, 89.9443776815231, 423.435...    4.239688   \n",
       "260036  [[43.29, 53.946000000000005, 138.5280000000000...    2.287371   \n",
       "260037  [[72.32877735181498, 72.32877735181498, 286.71...    4.628412   \n",
       "260038  [[159.29999999999998, 101.69999999999999, 288....    4.098548   \n",
       "260039  [[128.1250527756009, 43.0283509252003, 170.193...    2.541669   \n",
       "260040  [[671.7425608596343, 711.1391820866717, 1024.3...    2.962549   \n",
       "260041  [[40.53708192757677, 80.53016385515353, 219.96...    4.443826   \n",
       "260042  [[571.7543840785293, 222.5500841594307, 735.16...    3.885471   \n",
       "260043  [[50.71985362501876, 67.43980483335834, 200.63...    4.274568   \n",
       "260044  [[150.39987441065605, 63.94571609681602, 201.7...    4.200974   \n",
       "260045  [[860.4282331567886, 689.0883865254309, 1165.1...    3.180328   \n",
       "260046                              [[41, 153, 112, 224]]    1.395016   \n",
       "260047                     [[253.5, 229.5, 360.0, 336.0]]    1.779573   \n",
       "260048  [[146.50879038499818, 170.76025544916453, 363....    2.926798   \n",
       "\n",
       "        second_face_score  age    maindir subdir  \\\n",
       "260030                NaN   38  imdb_crop     41   \n",
       "260031           4.542781   31  imdb_crop     41   \n",
       "260032           2.611601   22  imdb_crop     41   \n",
       "260033                NaN   38  imdb_crop     41   \n",
       "260034           2.727795   39  imdb_crop     41   \n",
       "260035                NaN   39  imdb_crop     41   \n",
       "260036           1.382159   22  imdb_crop     41   \n",
       "260037                NaN   22  imdb_crop     41   \n",
       "260038                NaN   22  imdb_crop     41   \n",
       "260039           1.700773   22  imdb_crop     41   \n",
       "260040           2.615386   31  imdb_crop     41   \n",
       "260041                NaN   38  imdb_crop     41   \n",
       "260042           3.381501   31  imdb_crop     41   \n",
       "260043                NaN   31  imdb_crop     41   \n",
       "260044           3.561390   31  imdb_crop     41   \n",
       "260045           2.096533   12  imdb_crop     41   \n",
       "260046                NaN   37  imdb_crop     41   \n",
       "260047           1.536040   38  imdb_crop     41   \n",
       "260048                NaN   37  imdb_crop     41   \n",
       "\n",
       "                                        filename  \n",
       "260030  nm0342241_rm1022358272_1971-7-9_2010.jpg  \n",
       "260031  nm0342241_rm1724627200_1971-7-9_2003.jpg  \n",
       "260032  nm0342241_rm1936167936_1971-7-9_1994.jpg  \n",
       "260033  nm0342241_rm2388233728_1971-7-9_2010.jpg  \n",
       "260034  nm0342241_rm2647042816_1971-7-9_2011.jpg  \n",
       "260035  nm0342241_rm2680597248_1971-7-9_2011.jpg  \n",
       "260036  nm0342241_rm3477179136_1971-7-9_1994.jpg  \n",
       "260037  nm0342241_rm3706427392_1971-7-9_1994.jpg  \n",
       "260038  nm0342241_rm3792738304_1971-7-9_1994.jpg  \n",
       "260039  nm0342241_rm4128282624_1971-7-9_1994.jpg  \n",
       "260040   nm0342241_rm416004352_1971-7-9_2003.jpg  \n",
       "260041  nm0342241_rm4241457664_1971-7-9_2010.jpg  \n",
       "260042   nm0342241_rm483113216_1971-7-9_2003.jpg  \n",
       "260043   nm0342241_rm558996224_1971-7-9_2003.jpg  \n",
       "260044   nm0342241_rm575773440_1971-7-9_2003.jpg  \n",
       "260045   nm0342241_rm696109056_1971-7-9_1984.jpg  \n",
       "260046   nm0342241_rm820224256_1971-7-9_2009.jpg  \n",
       "260047   nm0342241_rm837808896_1971-7-9_2010.jpg  \n",
       "260048   nm0342241_rm853778688_1971-7-9_2009.jpg  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb[df_imdb['name']=='Scott Grimes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#im going to ignore the extranneous information since the images are already cropped\n",
    "df_imdb = df_imdb[['maindir', 'subdir', 'filename', 'name', 'gender', 'age']]\n",
    "df_wiki = df_wiki[['maindir', 'subdir', 'filename', 'name', 'gender', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (296016, 6)\n",
      "test: (126865, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maindir</th>\n",
       "      <th>subdir</th>\n",
       "      <th>filename</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wiki_crop</td>\n",
       "      <td>06</td>\n",
       "      <td>7297606_1980-07-25_2014.jpg</td>\n",
       "      <td>Sven Järve</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>14</td>\n",
       "      <td>nm0001814_rm146321408_1952-7-24_2008.jpg</td>\n",
       "      <td>Gus Van Sant</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>99</td>\n",
       "      <td>nm0001099_rm3767262976_1955-2-19_2013.jpg</td>\n",
       "      <td>Jeff Daniels</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>38</td>\n",
       "      <td>nm0001938_rm681807104_1944-8-4_2010.jpg</td>\n",
       "      <td>Richard Belzer</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imdb_crop</td>\n",
       "      <td>16</td>\n",
       "      <td>nm1143816_rm2716065024_1982-6-29_2011.jpg</td>\n",
       "      <td>Lily Rabe</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     maindir subdir                                   filename  \\\n",
       "0  wiki_crop     06                7297606_1980-07-25_2014.jpg   \n",
       "1  imdb_crop     14   nm0001814_rm146321408_1952-7-24_2008.jpg   \n",
       "2  imdb_crop     99  nm0001099_rm3767262976_1955-2-19_2013.jpg   \n",
       "3  imdb_crop     38    nm0001938_rm681807104_1944-8-4_2010.jpg   \n",
       "4  imdb_crop     16  nm1143816_rm2716065024_1982-6-29_2011.jpg   \n",
       "\n",
       "             name  gender  age  \n",
       "0      Sven Järve       1   33  \n",
       "1    Gus Van Sant       1   55  \n",
       "2    Jeff Daniels       1   57  \n",
       "3  Richard Belzer       1   65  \n",
       "4       Lily Rabe       0   28  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#only thing i dont like about this is that the same people are in train and test (you can smartly avoid this gut then the gender and age variation is a lot lower; so consider it a validation dataset)\n",
    "df_imdb_train, df_imdb_test = train_test_split(df_imdb, train_size=0.7, test_size=0.3, stratify=df_imdb['gender'], random_state=42, shuffle=True)\n",
    "df_wiki_train, df_wiki_test = train_test_split(df_wiki, train_size=0.7, test_size=0.3, stratify=df_wiki['gender'], random_state=42, shuffle=True)\n",
    "\n",
    "df_train = pd.concat([df_imdb_train, df_wiki_train], axis=0)\n",
    "df_test = pd.concat([df_imdb_test, df_wiki_test], axis=0)\n",
    "\n",
    "#shuffle\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(f'train: {df_train.shape}')\n",
    "print(f'test: {df_test.shape}')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Output annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_imdb.to_csv('C:\\\\Users\\\\nick\\\\tensorflow_datasets\\\\downloads\\\\manual\\\\imdb_wiki\\\\train_ann.csv', index=False)\n",
    "df_wiki.to_csv('C:\\\\Users\\\\nick\\\\tensorflow_datasets\\\\downloads\\\\manual\\\\imdb_wiki\\\\test_ann.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Wiki has broken images so search for them and remove them\n",
    "\n",
    "*Looks like they just removed them from the annotation file which is fine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df_imdb = pd.read_csv('C:\\\\Users\\\\nick\\\\tensorflow_datasets\\\\downloads\\\\manual\\\\imdb_wiki\\\\train_ann.csv')\n",
    "df_wiki = pd.read_csv('C:\\\\Users\\\\nick\\\\tensorflow_datasets\\\\downloads\\\\manual\\\\imdb_wiki\\\\test_ann.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\nick\\\\tensorflow_datasets\\\\downloads\\\\manual\\\\imdb_wiki\\\\imdb_crop\\\\53\\\\nm0005453_rm2397869312_1981-12-2_2010.jpg',\n",
       " 'C:\\\\Users\\\\nick\\\\tensorflow_datasets\\\\downloads\\\\manual\\\\imdb_wiki\\\\imdb_crop\\\\70\\\\nm1692270_rm1524542976_1986-11-1_2011.jpg',\n",
       " 'C:\\\\Users\\\\nick\\\\tensorflow_datasets\\\\downloads\\\\manual\\\\imdb_wiki\\\\imdb_crop\\\\05\\\\nm0425005_rm1812570368_1972-5-2_2013.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indir = 'C:\\\\Users\\\\nick\\\\tensorflow_datasets\\\\downloads\\\\manual\\\\imdb_wiki'\n",
    "def get_paths(df):\n",
    "    subdirs = ['0'+x if len(x)==1 else x for x in df.subdir.astype(str)]\n",
    "    return  [os.path.join(indir, maindir, subdir, filename) for  maindir, subdir, filename in zip(df.maindir, subdirs, df.filename)]\n",
    "img_paths = list(set(get_paths(df_imdb) + get_paths(df_wiki)))\n",
    "img_paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal img size: 2000\n",
      "Bad img size: 333\n"
     ]
    }
   ],
   "source": [
    "empty_img_ex = 'C:\\\\Users\\\\nick\\\\tensorflow_datasets\\\\downloads\\\\manual\\\\imdb_wiki\\\\wiki_crop\\\\00\\\\2658600_1980-11-03_2012.jpg'\n",
    "print(f'Normal img size: {os.path.getsize(img_paths[0])}')\n",
    "#notice not zero since the file is still named\n",
    "print(f'Bad img size: {os.path.getsize(empty_img_ex)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_imgs = [x for x in img_paths if os.path.getsize(x)<400]\n",
    "print(len(bad_imgs))\n",
    "bad_imgs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# #make sure some of the names dont overlap\n",
    "# import jellyfish\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# imdb_names = list(set(df_imdb.name))\n",
    "# wiki_names = list(set(df_wiki.name))\n",
    "\n",
    "# for imdb in tqdm(imdb_names):\n",
    "#     for wiki in wiki_names:\n",
    "#         distance = jellyfish.jaro_distance(imdb, wiki)\n",
    "#         if 0.9 < distance < 1.0:\n",
    "#             print(f'Wiki: {wiki},\\t IMDB: {imdb},\\t {distance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "DS-9rLTR065l"
   },
   "source": [
    "# TensorFlow Datasets\n",
    "\n",
    "TFDS provides a way to transform all those datasets into a standard format, do the preprocessing necessary to make them ready for a machine learning pipeline, and provides a standard input pipeline using `tf.data`.\n",
    "\n",
    "To enable this, each dataset implements a subclass of `DatasetBuilder`, which specifies:\n",
    "\n",
    "* Where the data is coming from (i.e. its URL). \n",
    "* What the dataset looks like (i.e. its features).  \n",
    "* How the data should be split (e.g. TRAIN and TEST). \n",
    "* The individual records in the dataset.\n",
    "\n",
    "The first time a dataset is used, the dataset is downloaded, prepared, and written to disk in a standard format. Subsequent access will read from those pre-processed files directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "6bGCSA-jX0Uw"
   },
   "source": [
    "## Clone the TFDS Repository\n",
    "\n",
    "The next step will be to clone the GitHub TFDS Repository. For this particular notebook, we will clone a particular version of the repository. You can clone the repository by running the following command:\n",
    "\n",
    "```\n",
    "!git clone https://github.com/tensorflow/datasets.git -b v1.2.0\n",
    "```\n",
    "\n",
    "However, for simplicity, we have already cloned this repository for you and placed the files locally. Therefore, there is no need to run the above command if you are running this notebook in Coursera environment.\n",
    "\n",
    "Next, we set the current working directory to `/datasets/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "KhYXnLCf5F-Y"
   },
   "outputs": [],
   "source": [
    "cd datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "6Fct97VEYxlT"
   },
   "source": [
    "If you want to contribute to TFDS' repo and add a new dataset, you can use the the following script to help you generate a template of the required python file. To use it, you must first clone the tfds repository and then run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "wZ3psFN65G9u"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python tensorflow_datasets/scripts/create_new_dataset.py \\\n",
    "  --dataset my_dataset \\\n",
    "  --type image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "a5UbwBVRTmb2"
   },
   "source": [
    "If you wish to see the template generated by the `create_new_dataset.py` file, navigate to the folder indicated in the above cell output. Then go to the `/image/` folder and look for a file called `my_dataset.py`. Feel free to open the file and inspect it. You will see a template with place holders, indicated with the word `TODO`, where you have to fill in the information. \n",
    "\n",
    "Now we will use IPython's `%%writefile` in-built magic command to write whatever is in the current cell into a file. To create or overwrite a file you can use:\n",
    "```\n",
    "%%writefile filename\n",
    "```\n",
    "\n",
    "Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "qkspG9KV7X7i"
   },
   "outputs": [],
   "source": [
    "%%writefile something.py\n",
    "x = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "TQ--c2h0K6R1"
   },
   "source": [
    "Now that the file has been written, let's inspect its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "VqBEa9UrK4-Z"
   },
   "outputs": [],
   "source": [
    "!cat something.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "UJT2Mh-bYmYa"
   },
   "source": [
    "## Define the Dataset with `GeneratorBasedBuilder`\n",
    "\n",
    "Most datasets subclass `tfds.core.GeneratorBasedBuilder`, which is a subclass of `tfds.core.DatasetBuilder` that simplifies defining a dataset. It works well for datasets that can be generated on a single machine. Its subclasses implement:\n",
    "\n",
    "* `_info`: builds the DatasetInfo object describing the dataset\n",
    "\n",
    "\n",
    "* `_split_generators`: downloads the source data and defines the dataset splits\n",
    "\n",
    "\n",
    "* `_generate_examples`: yields (key, example) tuples in the dataset from the source data\n",
    "\n",
    "In this exercise, you will use the `GeneratorBasedBuilder`.\n",
    "\n",
    "### EXERCISE: Fill in the missing code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "cYyTvIoO7FqS"
   },
   "outputs": [],
   "source": [
    "%%writefile tensorflow_datasets/image/imdb_faces.py\n",
    "\n",
    "# coding=utf-8\n",
    "# Copyright 2019 The TensorFlow Datasets Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"IMDB Faces dataset.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "\n",
    "_DESCRIPTION = \"\"\"\\\n",
    "Since the publicly available face image datasets are often of small to medium size, rarely exceeding tens of thousands of images, and often without age information we decided to collect a large dataset of celebrities. For this purpose, we took the list of the most popular 100,000 actors as listed on the IMDb website and (automatically) crawled from their profiles date of birth, name, gender and all images related to that person. Additionally we crawled all profile images from pages of people from Wikipedia with the same meta information. We removed the images without timestamp (the date when the photo was taken). Assuming that the images with single faces are likely to show the actor and that the timestamp and date of birth are correct, we were able to assign to each such image the biological (real) age. Of course, we can not vouch for the accuracy of the assigned age information. Besides wrong timestamps, many images are stills from movies - movies that can have extended production times. In total we obtained 460,723 face images from 20,284 celebrities from IMDb and 62,328 from Wikipedia, thus 523,051 in total.\n",
    "\n",
    "As some of the images (especially from IMDb) contain several people we only use the photos where the second strongest face detection is below a threshold. For the network to be equally discriminative for all ages, we equalize the age distribution for training. For more details please the see the paper.\n",
    "\"\"\"\n",
    "\n",
    "_URL = (\"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\")\n",
    "_IMDB_DATASET_ROOT_DIR = \"imdb_crop\"\n",
    "_IMDB_ANNOTATION_FILE = \"imdb.mat\"\n",
    "_WIKI_DATASET_ROOT_DIR = \"wiki_crop\"\n",
    "_WIKI_META_DATASET_ROOT_DIR = \"wiki\"\n",
    "_WIKI_ANNOTATION_FILE = \"imdb.mat\"\n",
    "\n",
    "\n",
    "_CITATION = \"\"\"\\\n",
    "@article{Rothe-IJCV-2016,\n",
    "  author = {Rasmus Rothe and Radu Timofte and Luc Van Gool},\n",
    "  title = {Deep expectation of real and apparent age from a single image without facial landmarks},\n",
    "  journal = {International Journal of Computer Vision},\n",
    "  volume={126},\n",
    "  number={2-4},\n",
    "  pages={144--157},\n",
    "  year={2018},\n",
    "  publisher={Springer}\n",
    "}\n",
    "@InProceedings{Rothe-ICCVW-2015,\n",
    "  author = {Rasmus Rothe and Radu Timofte and Luc Van Gool},\n",
    "  title = {DEX: Deep EXpectation of apparent age from a single image},\n",
    "  booktitle = {IEEE International Conference on Computer Vision Workshops (ICCVW)},\n",
    "  year = {2015},\n",
    "  month = {December},\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Source URL of the IMDB faces dataset\n",
    "_IMDB_TARBALL_URL = \"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\"\n",
    "_WIKI_TARBALL_URL = \"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\"\n",
    "_WIKI_META_TARBALL_URL = \"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki.tar.gz\"\n",
    "\n",
    "\n",
    "\n",
    "class ImdbWikiFaces(tfds.core.GeneratorBasedBuilder):\n",
    "    \"\"\"IMDB-Wiki Faces dataset.\"\"\"\n",
    "\n",
    "    VERSION = tfds.core.Version(\"0.1.0\")\n",
    "\n",
    "    def _info(self):\n",
    "        return tfds.core.DatasetInfo(\n",
    "            builder=self,\n",
    "            description=_DESCRIPTION,\n",
    "            # Describe the features of the dataset by following this url\n",
    "            # https://www.tensorflow.org/datasets/api_docs/python/tfds/features\n",
    "            features=tfds.features.FeaturesDict({\n",
    "                \"image\": tfds.features.Image(),\n",
    "                \"gender\": tfds.features.ClassLabel(num_classes=2),\n",
    "                \"dob\": tf.int32,\n",
    "                \"photo_taken\": tf.int32,\n",
    "                \"face_location\": tfds.features.BBoxFeature(),\n",
    "                \"face_score\": tf.float32,\n",
    "                \"second_face_score\": tf.float32,\n",
    "                \"celeb_id\": tf.int32\n",
    "            }),\n",
    "            supervised_keys=(\"image\", \"gender\"),\n",
    "            urls=[_URL],\n",
    "            citation=_CITATION)\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "        # Download the dataset and then extract it.\n",
    "        imdb_download_path = dl_manager.download([_IMDB_TARBALL_URL])\n",
    "        imdb_extracted_path = dl_manager.download_and_extract([_IMDB_TARBALL_URL])\n",
    "        \n",
    "        wiki_download_path = dl_manager.download([_WIKI_TARBALL_URL])\n",
    "        wiki_extracted_path = dl_manager.download_and_extract([_WIKI_TARBALL_URL])\n",
    "        \n",
    "        wiki_meta_download_path = dl_manager.download([_WIKI_META_TARBALL_URL])\n",
    "        wiki_meta_extracted_path = dl_manager.download_and_extract([_WIKI_META_TARBALL_URL])\n",
    "        \n",
    "        \n",
    "        data_dirs = dl_manager.download_and_extract({\n",
    "            'imdb_crop': _IMDB_TARBALL_URL_IMDB_TARBALL_URL,\n",
    "            'wiki_crop': _WIKI_TARBALL_URL,\n",
    "            'wiki': _WIKI_META_TARBALL_URL\n",
    "        })\n",
    "\n",
    "        # Parsing the mat file which contains the list of train images\n",
    "        def parse_mat_file(file_name, dataset):\n",
    "            with tf.io.gfile.GFile(file_name, \"rb\") as f:\n",
    "                # Add a lazy import for scipy.io and import the loadmat method to \n",
    "                # load the annotation file\n",
    "                imdb_dataset = tfds.core.lazy_imports.scipy.io.loadmat(file_name)[dataset]\n",
    "            return dataset\n",
    "\n",
    "        # Parsing the mat file by using scipy's loadmat method\n",
    "        # Pass the path to the annotation file using the downloaded/extracted paths above\n",
    "        imdb_meta = parse_mat_file(os.path.join(data_dirs['imdb_crop'], _IMDB_DATASET_ROOT_DIR, _IMDB_ANNOTATION_FILE), 'imdb')\n",
    "        wiki_meta = parse_mat_file(os.path.join(data_dirs['wiki_crop'], _WIKI_META_DATASET_ROOT_DIR, _WIKI_ANNOTATION_FILE), 'wiki')\n",
    "\n",
    "        # Get the names of celebrities from the metadata\n",
    "        celeb_names = meta[0, 0][\"celeb_names\"][0]\n",
    "\n",
    "        # Create tuples out of the distinct set of genders and celeb names\n",
    "        self.info.features['gender'].names = ['Female', 'Male']\n",
    "        self.info.features['celeb_id'].names = tuple([x[0] for x in celeb_names])\n",
    "\n",
    "        return [\n",
    "            tfds.core.SplitGenerator(\n",
    "                name=tfds.Split.TRAIN,\n",
    "                gen_kwargs={\n",
    "                    \"image_dir\": extracted_path[0],\n",
    "                    \"metadata\": meta,\n",
    "                })\n",
    "        ]\n",
    "\n",
    "    def _get_bounding_box_values(self, bbox_annotations, img_width, img_height):\n",
    "        \"\"\"Function to get normalized bounding box values.\n",
    "\n",
    "        Args:\n",
    "          bbox_annotations: list of bbox values in kitti format\n",
    "          img_width: image width\n",
    "          img_height: image height\n",
    "\n",
    "        Returns:\n",
    "          Normalized bounding box xmin, ymin, xmax, ymax values\n",
    "        \"\"\"\n",
    "\n",
    "        ymin = bbox_annotations[0] / img_height\n",
    "        xmin = bbox_annotations[1] / img_width\n",
    "        ymax = bbox_annotations[2] / img_height\n",
    "        xmax = bbox_annotations[3] / img_width\n",
    "        return ymin, xmin, ymax, xmax\n",
    "  \n",
    "    def _get_image_shape(self, image_path):\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_image(image, channels=3)\n",
    "        shape = image.shape[:2]\n",
    "        return shape\n",
    "\n",
    "    def _generate_examples(self, image_dir, metadata):\n",
    "        # Add a lazy import for pandas here (pd)\n",
    "        pd = tfds.core.lazy_imports.pandas\n",
    "\n",
    "        # Extract the root dictionary from the metadata so that you can query all the keys inside it\n",
    "        root = metadata[0, 0]\n",
    "\n",
    "        \"\"\"Extract image names, dobs, genders,  \n",
    "                   face locations, \n",
    "                   year when the photos were taken,\n",
    "                   face scores (second face score too),\n",
    "                   celeb ids\n",
    "        \"\"\"\n",
    "        image_names = root[\"full_path\"][0]\n",
    "        # Do the same for other attributes (dob, genders etc)\n",
    "        dobs = root[\"dob\"][0]\n",
    "        genders = root[\"gender\"][0]\n",
    "        photo_taken_years = root[\"photo_taken\"][0]\n",
    "        face_scores = root[\"face_score\"][0]\n",
    "        face_locations = root[\"face_location\"][0]\n",
    "        second_face_scores = root[\"second_face_score\"][0]\n",
    "        celeb_id = root[\"celeb_id\"][0]\n",
    "\n",
    "        # Now create a dataframe out of all the features like you've seen before\n",
    "        df = pd.DataFrame(list(zip(image_names,\n",
    "                                   dobs,\n",
    "                                   genders,\n",
    "                                   photo_taken_years,\n",
    "                                   face_scores,\n",
    "                                   face_locations,\n",
    "                                   second_face_scores,\n",
    "                                   celeb_id\n",
    "                                  )),\n",
    "                          columns=['image_names', 'dobs', 'genders', 'photo_taken_years',\n",
    "                                   'face_scores', 'face_locations', 'second_face_scores',\n",
    "                                   'celeb_ids'])\n",
    "\n",
    "        # Filter dataframe by only having the rows with face_scores > 1.0\n",
    "        df = df[df['face_scores']>1.0]\n",
    "\n",
    "\n",
    "        # Remove any records that contain Nulls/NaNs by checking for NaN with .isna()\n",
    "        df = df[~df['genders'].isna()]\n",
    "        df = df[~df['second_face_scores'].isna()]\n",
    "\n",
    "        # Cast genders to integers so that mapping can take place\n",
    "        df.genders = df.genders.astype(int)\n",
    "\n",
    "        # Iterate over all the rows in the dataframe and map each feature\n",
    "        for _, row in df.iterrows():\n",
    "            # Extract filename, gender, dob, photo_taken, \n",
    "            # face_score, second_face_score and celeb_id\n",
    "            filename = os.path.join(image_dir, _DATASET_ROOT_DIR, row['image_names'][0])\n",
    "            gender = row['genders']\n",
    "            dob = row['dobs']\n",
    "            photo_taken = row['photo_taken_years']\n",
    "            face_score = row['face_scores']\n",
    "            second_face_score = row['second_face_scores']\n",
    "            celeb_id = row['celeb_ids']\n",
    "\n",
    "            # Get the image shape\n",
    "            image_width, image_height = self._get_image_shape(filename)\n",
    "            # Normalize the bounding boxes by using the face coordinates and the image shape\n",
    "            bbox = self._get_bounding_box_values(row['face_locations'][0], \n",
    "                                               image_width, image_height)\n",
    "\n",
    "            # Yield a feature dictionary \n",
    "            yield filename, {\n",
    "              \"image\": filename,\n",
    "              \"gender\": gender,\n",
    "              \"dob\": dob,\n",
    "              \"photo_taken\": photo_taken,\n",
    "              \"face_location\": tfds.features.BBox(ymin=min(bbox[0], 1.0),\n",
    "                                                  xmin=min(bbox[1], 1.0),\n",
    "                                                  ymax=min(bbox[2], 1.0),\n",
    "                                                  xmax=min(bbox[3], 1.0)),\n",
    "              \"face_score\": face_score,\n",
    "              \"second_face_score\": second_face_score,\n",
    "              \"celeb_id\": celeb_id\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "7Lu65xXYZC8m"
   },
   "source": [
    "## Add an Import for Registration\n",
    "\n",
    "All subclasses of `tfds.core.DatasetBuilder` are automatically registered when their module is imported such that they can be accessed through `tfds.builder` and `tfds.load`.\n",
    "\n",
    "If you're contributing the dataset to `tensorflow/datasets`, you must add the module import to its subdirectory's `__init__.py` (e.g. `image/__init__.py`), as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "pKC49eVJXJLe"
   },
   "outputs": [],
   "source": [
    "%%writefile tensorflow_datasets/image/__init__.py\n",
    "# coding=utf-8\n",
    "# Copyright 2019 The TensorFlow Datasets Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Image datasets.\"\"\"\n",
    "\n",
    "from tensorflow_datasets.image.abstract_reasoning import AbstractReasoning\n",
    "from tensorflow_datasets.image.aflw2k3d import Aflw2k3d\n",
    "from tensorflow_datasets.image.bigearthnet import Bigearthnet\n",
    "from tensorflow_datasets.image.binarized_mnist import BinarizedMNIST\n",
    "from tensorflow_datasets.image.binary_alpha_digits import BinaryAlphaDigits\n",
    "from tensorflow_datasets.image.caltech import Caltech101\n",
    "from tensorflow_datasets.image.caltech_birds import CaltechBirds2010\n",
    "from tensorflow_datasets.image.cats_vs_dogs import CatsVsDogs\n",
    "from tensorflow_datasets.image.cbis_ddsm import CuratedBreastImagingDDSM\n",
    "from tensorflow_datasets.image.celeba import CelebA\n",
    "from tensorflow_datasets.image.celebahq import CelebAHq\n",
    "from tensorflow_datasets.image.chexpert import Chexpert\n",
    "from tensorflow_datasets.image.cifar import Cifar10\n",
    "from tensorflow_datasets.image.cifar import Cifar100\n",
    "from tensorflow_datasets.image.cifar10_corrupted import Cifar10Corrupted\n",
    "from tensorflow_datasets.image.clevr import CLEVR\n",
    "from tensorflow_datasets.image.coco import Coco\n",
    "from tensorflow_datasets.image.coco2014_legacy import Coco2014\n",
    "from tensorflow_datasets.image.coil100 import Coil100\n",
    "from tensorflow_datasets.image.colorectal_histology import ColorectalHistology\n",
    "from tensorflow_datasets.image.colorectal_histology import ColorectalHistologyLarge\n",
    "from tensorflow_datasets.image.cycle_gan import CycleGAN\n",
    "from tensorflow_datasets.image.deep_weeds import DeepWeeds\n",
    "from tensorflow_datasets.image.diabetic_retinopathy_detection import DiabeticRetinopathyDetection\n",
    "from tensorflow_datasets.image.downsampled_imagenet import DownsampledImagenet\n",
    "from tensorflow_datasets.image.dsprites import Dsprites\n",
    "from tensorflow_datasets.image.dtd import Dtd\n",
    "from tensorflow_datasets.image.eurosat import Eurosat\n",
    "from tensorflow_datasets.image.flowers import TFFlowers\n",
    "from tensorflow_datasets.image.food101 import Food101\n",
    "from tensorflow_datasets.image.horses_or_humans import HorsesOrHumans\n",
    "from tensorflow_datasets.image.image_folder import ImageLabelFolder\n",
    "from tensorflow_datasets.image.imagenet import Imagenet2012\n",
    "from tensorflow_datasets.image.imagenet2012_corrupted import Imagenet2012Corrupted\n",
    "from tensorflow_datasets.image.kitti import Kitti\n",
    "from tensorflow_datasets.image.lfw import LFW\n",
    "from tensorflow_datasets.image.lsun import Lsun\n",
    "from tensorflow_datasets.image.mnist import EMNIST\n",
    "from tensorflow_datasets.image.mnist import FashionMNIST\n",
    "from tensorflow_datasets.image.mnist import KMNIST\n",
    "from tensorflow_datasets.image.mnist import MNIST\n",
    "from tensorflow_datasets.image.mnist_corrupted import MNISTCorrupted\n",
    "from tensorflow_datasets.image.omniglot import Omniglot\n",
    "from tensorflow_datasets.image.open_images import OpenImagesV4\n",
    "from tensorflow_datasets.image.oxford_flowers102 import OxfordFlowers102\n",
    "from tensorflow_datasets.image.oxford_iiit_pet import OxfordIIITPet\n",
    "from tensorflow_datasets.image.patch_camelyon import PatchCamelyon\n",
    "from tensorflow_datasets.image.pet_finder import PetFinder\n",
    "from tensorflow_datasets.image.quickdraw import QuickdrawBitmap\n",
    "from tensorflow_datasets.image.resisc45 import Resisc45\n",
    "from tensorflow_datasets.image.rock_paper_scissors import RockPaperScissors\n",
    "from tensorflow_datasets.image.scene_parse_150 import SceneParse150\n",
    "from tensorflow_datasets.image.shapes3d import Shapes3d\n",
    "from tensorflow_datasets.image.smallnorb import Smallnorb\n",
    "from tensorflow_datasets.image.so2sat import So2sat\n",
    "from tensorflow_datasets.image.stanford_dogs import StanfordDogs\n",
    "from tensorflow_datasets.image.stanford_online_products import StanfordOnlineProducts\n",
    "from tensorflow_datasets.image.sun import Sun397\n",
    "from tensorflow_datasets.image.svhn import SvhnCropped\n",
    "from tensorflow_datasets.image.uc_merced import UcMerced\n",
    "from tensorflow_datasets.image.visual_domain_decathlon import VisualDomainDecathlon\n",
    "\n",
    "# EXERCISE: Import your dataset module here\n",
    "\n",
    "from tensorflow_datasets.image.imdb_faces import ImdbFaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "QYmgS2SrYXtP"
   },
   "source": [
    "## URL Checksums\n",
    "\n",
    "If you're contributing the dataset to `tensorflow/datasets`, add a checksums file for the dataset. On first download, the DownloadManager will automatically add the sizes and checksums for all downloaded URLs to that file. This ensures that on subsequent data generation, the downloaded files are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "cvrp-iHuYG_e"
   },
   "outputs": [],
   "source": [
    "!touch tensorflow_datasets/url_checksums/imdb_faces.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "JwnUAn49U-U8"
   },
   "source": [
    "## Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "Y8uKiqWrU_C0"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Fill in the name of your dataset.\n",
    "# The name must be a string.\n",
    "DATASET_NAME = \"imdb_faces\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "S7evoTtpon7I"
   },
   "source": [
    "We then run the `download_and_prepare` script locally to build it, using the following command:\n",
    "\n",
    "```\n",
    "%%bash -s $DATASET_NAME\n",
    "python -m tensorflow_datasets.scripts.download_and_prepare \\\n",
    "  --register_checksums \\\n",
    "  --datasets=$1\n",
    "```\n",
    "\n",
    "**NOTE:** It may take more than 30 minutes to download the dataset and then write all the preprocessed files as TFRecords. Due to the enormous size of the data involved, we are unable to run the above script in the Coursera environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "7hNPD2rraN5o"
   },
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Once the dataset is built you can load it in the usual way, by using `tfds.load`, as shown below:\n",
    "\n",
    "```python\n",
    "import tensorflow_datasets as tfds\n",
    "dataset, info = tfds.load('imdb_faces', with_info=True)\n",
    "```\n",
    "\n",
    "**Note:** Since we couldn't build the `imdb_faces` dataset due to its size, we are unable to run the above code in the Coursera environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Explore the Dataset\n",
    "\n",
    "Once the dataset is loaded, you can explore it by using the following loop:\n",
    "\n",
    "```python\n",
    "for feature in tfds.as_numpy(dataset['train']):\n",
    "  for key, value in feature.items():\n",
    "    if key == 'image':\n",
    "      value = value.shape\n",
    "    print(key, value)\n",
    "  break\n",
    "```\n",
    "\n",
    "**Note:** Since we couldn't build the `imdb_faces` dataset due to its size, we are unable to run the above code in the Coursera environment.\n",
    "\n",
    "The expected output from the code block shown above should be:\n",
    "\n",
    "```python\n",
    ">>>\n",
    "celeb_id 12387\n",
    "dob 722957\n",
    "face_location [1.         0.56327355 1.         1.        ]\n",
    "face_score 4.0612864\n",
    "gender 0\n",
    "image (96, 97, 3)\n",
    "photo_taken 2007\n",
    "second_face_score 3.6680346\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "BhUO2vXDZw8q"
   },
   "source": [
    "# Next steps for publishing\n",
    "\n",
    "**Double-check the citation**  \n",
    "\n",
    "It's important that DatasetInfo.citation includes a good citation for the dataset. It's hard and important work contributing a dataset to the community and we want to make it easy for dataset users to cite the work.\n",
    "\n",
    "If the dataset's website has a specifically requested citation, use that (in BibTex format).\n",
    "\n",
    "If the paper is on arXiv, find it there and click the bibtex link on the right-hand side.\n",
    "\n",
    "If the paper is not on arXiv, find the paper on Google Scholar and click the double-quotation mark underneath the title and on the popup, click BibTeX.\n",
    "\n",
    "If there is no associated paper (for example, there's just a website), you can use the BibTeX Online Editor to create a custom BibTeX entry (the drop-down menu has an Online entry type).\n",
    "  \n",
    "\n",
    "**Add a test**   \n",
    "\n",
    "Most datasets in TFDS should have a unit test and your reviewer may ask you to add one if you haven't already. See the testing section below.   \n",
    "**Check your code style**  \n",
    "\n",
    "Follow the PEP 8 Python style guide, except TensorFlow uses 2 spaces instead of 4. Please conform to the Google Python Style Guide,\n",
    "\n",
    "Most importantly, use tensorflow_datasets/oss_scripts/lint.sh to ensure your code is properly formatted. For example, to lint the image directory\n",
    "See TensorFlow code style guide for more information.\n",
    "\n",
    "**Add release notes**\n",
    "Add the dataset to the release notes. The release note will be published for the next release.\n",
    "\n",
    "**Send for review!**\n",
    "Send the pull request for review.\n",
    "\n",
    "For more information, visit https://www.tensorflow.org/datasets/add_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This frees up resources for your fellow learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Shutdown and close the notebook -->\n",
    "window.onbeforeunload = null\n",
    "window.close();\n",
    "IPython.notebook.session.delete();"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TFDS Week 4 - Question.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "coursera": {
   "course_slug": "data-pipelines-tensorflow",
   "graded_item_id": "fqOvf",
   "launcher_item_id": "QCJEw"
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
